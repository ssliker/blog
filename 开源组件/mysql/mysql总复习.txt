1.mysql操作sql：
    1.mysql-用户、密码、权限管理
        1.新建
        CREATE USER 'uname'@'host' IDENTIFIED BY PASSWORD('XXX')
        CREATE USER 'uname'@'host';
        2.删除
        DROP USER 'uname'@'host';
        4.重设密码
        SET PASSWORD FOR 'uname'@'host' = PASSWORD('password')
        5.授权
        GRANT ALL PRIVILEGES ON dbname.tablename TO 'uname'@'host'
        GRANT ALL ON dbname.* TO 'uname'@'host'
        GRANT select,insert,update,delete ON *.* TO 'uname'@'host'
        6.去权
        REVOKE ALL ON dbname.tablename FROM 'uname'@'host'
        REVOKE select ON *.* FROM 'uname'@'host'
        7.查权
        SHOW GRANTS;
        SHOW GRANTS FOR 'uname'@'host'；

    2.数据库操作
        1.建库：
            CREATE DATABASE IF NOT EXISTS dbname;
        2.查询数据库列表
            SHOW DATABASES;
        3.选择数据库
            USE dbname;
        4.删除数据库
            DROP DATABASES dbname;
    3.数据表操作
        1.建表
            CREATE TABLE dbname.tablename (
                fild_name data_type(limit)[unsigned] null/not null default 0 AUTO_INCREMENT comment '',
                primary key (`fild`) USING BTREE,
                unique key `key_name` (`fild`) USING BTREE,
                key `p_k` (`fild1`,`fild2`) USING BTREE
            )
            ENGINE=Innodb AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='';
        
        2.查：
            show create table tablename;
        
        3.删表：
            drop table tablename;
        
        4.查库中所有表：
            show tables;
        
        5.改表：
            字段变更
            增
            alter table tablename add fild ....
            alter table tablename add fild ... after origin fild
            删
            alter table tablename drop column fild;
            改
            alter table tablename modify fild new_attribute ...;
            alter table tablename change old_fildname new old_fildname ... ;
            索引变更
            增：
            alter table tablename add primiry key(`fild`)
            alter table tablename add unique keyname (`fild`)
            alter table tablename add index keyname (`fild`)
            删：
            alter table tablename drop primary key;
            alter table tablename drop index keyname;
            改：

    4.数据操作：
        1.增：
            普通插入结构；
                # 给指定字段插入值
                insert into tablename(fild1,fild2,fild3) values(v1,v2,v3);
                # 给所有字段插入值
                insert into tablename values(v1,v2,v3);
                # 一次插入多个值
                insert into tablename(fild1,fild2,fild3) values(v1,v2,v3),(v1,v2,v3),(v1,v2,v3)...;
                # 查询其他表中的数据插入当前表
                insert into tablename(fild1,fild2,fild3) select f1,f2,f3 from tablename ...;
            避免重复插入结构：
                1.直接忽略重复数据
                insert ignore into tablename(fild1,fild2,fild3) values(v1,v2,v3); -- 存在则忽略，不存在则插入(检测条件：唯一索引/主键)
                2.按照指定字段检测
                insert into tablename(fild1,fild2,fild3) values(v1,v2,v3) on duplicate key update fild1=v1,fild2=v2; -- 如果fild1=v1或者fild2=v2已经存在，则忽略，否则插入（检测条件：主键/唯一索引）
                3.先删除已经存在的数据，后插入
                replace into tablename(fild1,fild2,fild3) values(v1,v2,v3); -- 存在则先删后插，不存在则直接插入(检测条件：主键/唯一索引)

        2.删：结构：
            delete from tablename where xxx order by xx,xx limit xx,xx;
            备注：
                delete from tablename：删除子句
                where xx：where子句
                order by xx,xx：排序子句
                limit xx,xx：限制子句
        
        3.改：结构:
            update tablename set f1=v1,f2=v2 where xxx order by xxx limit xxx;
            备注：
                update tablename set f1=v1,f2=v2，vx可以是子查询，且必须是返回单行单列的二级嵌套子查询,如下：
                    update tablename set f1=(select v1 from (select v1 from tablenewname where id = 1) tmp );
                where xx：where子句
                order by xx,xx：排序子句
                limit xx：限制子句
        4.查：结构：
            select fild from tablename where xxx group by xx,xx having xx order by xx,xx limit xx,xx;
            备注:
                1.select子句：
                    结构：select 【distinct】 fild：
                    1.查询子句，待查询内容；
                    2.每一个fild都会在结果集中产生一个列，fild名称即为列名称，如果fild是常量的话，那么该常量就是列名称；
                    3.fild可以是字段、常量、函数、子查询，或者所有字段：*；
                    4.fild可以通过as设置别名；
                    5.distinct用来对结果集去重，去重时按照数据行一整行所有fild为依据进行去重。
                2.from子句：
                    结构：from tablename
                    1.from子句，表示数据来源。
                    2.tablename可以是单个表名，多个表名，子查询；
                    3.tablename类型不同，待查fild不同：
                        1.是单个表时，查询fild可以直接使用字段名，或者表名.字段名
                        2.是多个表时，查询fild必须使用数据表名.字段名。
                        3.是子查询结果时，可以使用子查询中的fild名称，或者子查询产生的临时表名.字段名来表示fild名；
                3.where子句：
                    结构：where 条件 and 条件 or 条件
                    1.where子句，表示对数据源中的数据进行条件过滤；
                    2.多个条件的连接：
                        1.在大的结构上由多个条件逻辑运算符(AND/OR)连接。
                        2.AND表示条件必须同时满足；OR表示任意一个
                        3.被连接的条件可以是同级条件，也可以是条件块。
                    3.where条件表达式：
                        1.数学条件判断：
                            = <>/!= >= <= < >
                        2.空值判断：
                            IS NULL
                            IS NOT NULL
                        3.区间判断：
                            BETWEEN a AND b
                            NOT BETWEEN a AND b
                        4.值存在性在判断：
                            IN (a,b,c)
                            NOT IN (a,b,c)
                        5.子查询存在性匹配：
                            EXISTS() 
                            NOT EXISTS()
                        6.存在匹配:
                            ANY()
                            NOT ANY()
                            SOME()
                            NOT SOME()
                        7.模糊匹配：
                            LIKE %a
                            LIKE a%
                            LIKE %a%
                            LIKE _a
                            LIKE a_
                            LIKE _a_
                            NOT LIKE %a
                            NOT LIKE a%
                            NOT LIKE %a%
                            NOT LIKE _a
                            NOT LIKE a_
                            NOT LIKE _a_
                    说明：
                        1.where条件中对字段过滤时不能使用select子句中as之后的别名；只能使用表中的字段名或者表明.字段名。
                        2.int、not in的()中放置的是具体的数据值，作用在于比对单个字段的值是否在in中存在;
                        3.exists、not exists()中放置的是一个子查询，如果子查询的结果不为空，那么条件就为true，外层查询将返回查询结果，否则返回空；
                        4.any、not any/some、not some()中放置的可以使具体的值或者返回单列单行/单列多行的子查询，用于字段条件筛选，表示字段只要满足其中一个值就满足条件。
                4.group by子句：
                    结构：group by fild1,fild2
                    1.用来按照指定的fild进行分组，支持对多个字段进行分组，多个字段分组时按照字段顺序依次分组，即多级分组；
                    2.多级分组中，需要注意一下三个点：
                        1.分组的语义：
                            数据记录：
                                A12->B-R12
                            按照两级分组：group by A,B
                                【A1->B->(r1,r2)】
                                【A2->B->(r1,r2)】
                                一共可以分出2个组。
                            按照三级分组：group by A,B,r
                                【A1->B->R1】
                                【A1->B->R2】
                                【A2->B->R1】
                                【A2->B->R2】
                                一共可以分出4个组
                            注：【】表示一个分组
                                ->表示该条分组记录中的相关字段
                                ()表示分组中的数据条数
                        2.分组查询中可以查询的数据：
                            1.分组查询中查询的记录结果只是该分组中的第一条数据；比如按照两级分组时，查询A1->B这个记录，那么R列最终返回的是R1；
                            2.聚合函数都是对每一个分组进行聚合计算的，比如计算数据条数COUNT，那么返回的是每一个分组中的数据条数，比如A1->B1这个记录，COUNT()之后的结果是2；

                5.having子句：
                    结构：having 条件列表
                    1.通常用在group by子句后面，对group by分组之后的记录进行过滤；
                    2.没有group by子句时，having也可以直接用在where子句之后，用来对where条件过滤之后的数据进行过滤。
                    3.having子句可以使用select子句中的fild来计算过滤条件，对于聚合了group by之后的fild也可以用在having字句中；

                6.order by子句：
                    结构：order by fild1,fild2
                    1.对结果集依次按照fild1，fild2进行排序；
                
                7.limit子句
                    结构：limit x,x
                    1.对结果集进行截取
                    2.变体有两种：limit x或者limit x,n
                    3.limit x：标识取结果集前x行返回；
                    4.limit x,n：表示从结果集低x行开始取n行返回；
    5.sql中常用的函数：
        1.聚合函数：
            说明：
                1.对结果进行聚合；
                2.其默认计算对象是where条件过滤之后的结果集；
                3.如果使用了group by，则计算对象变为每个分组；

            MAX(fild)/MAX(DISTINCT fild)：返回指定列中的最大值；带DISTINCT时只计算不同的值。
            MIN(fild)/MIN(DISTINCT fild)：返回指定列中的最小值；带DISTINCT时只计算不同的值。
            AVG(fild)/AVG(DISTINCT fild)：返回指定列的平均值；带DISTINCT时只计算不同的值。
            SUM(fild)/SUM(DISTINCT fild)：返回指定列的总和；带DISTINCT时只计算不同的值。
            COUNT()：返回结果集条数：有三种变体：
                1.COUNT(*)：返回结果集条数，某个字段为null时仍会统计该行记录。
                2.COUNT(1)：返回结果集条数，某个字段为null时仍会统计该行记录。COUNT(1)中的1只是起到占位左用，并无实际意义，COUNT(1)和COUNT(99)是等效的；
                3.count(fild)：返回结果集条数，fild字段为null时不会统计该行记录。
            说明：
                1.整体效率：COUNT(*)>=COUNT(1)>COUNT(主键)>COUNT(字段)
                2.MYISAM存储引擎在无条件查询COUNT时效率很高，因为其直接存储了数据记录条数，但是在有条件过滤之后，效率将变差，需要逐行统计。
            
        2.数值函数：
            ABS(x)：取x的绝对值；
            CEIL(x)：向上取整；
            FLOOR(x)：向下取整；
            MOD(x,y)：取x与y的模；
            ROUND(x,y)：返回x四舍五入保留y位小数之后的值；
            TRUNCATE(x,y)：返回x截断并保留y位小数之后的值；
            RAND()：返回0-1之间的随机值；
        3.字符串函数：
            UPPER(x)/LOWER(x)：返回x的大写/小写；
            LEFT(x)/RIGHT(x)：返回x左侧/右侧的字符;
            LTRIM(x)/RTRIM(x)/TRIM(x)：去除x左侧/右侧/两侧空格；
            REPLACE(str,a,b)：使用b替换str中所有的a；
            CONCAT(s1,s2,s3...)：将s1,s2,s3拼接成为一个字符串，连接符为空，如果有任意一个连接参数为null，将会返回null；
            CONCAT_WS(join,s1,s2...)：指定连接符拼接字符串，如果某个连接参数为null，不影响整体字符串的连接；
            GROUP_CONCAT(fild)：用在有GROUP BY子句的查询语句中，表示将每一个分组中相同的指定字段连接起来，默认用英文逗号连接，详细语法：
                GROUP_CONCAT( [distinct] 要连接的字段 [order by 排序字段 asc/desc  ] [separator '分隔符'] )
        4.日期时间函数：
            CURRENT_DATE()：当前日期，yyyy-MM-dd
            CURRENT_TIME()：当前时间，HH:mm:ss
            CURRENT_TIMESTAMP()：当前日期时间，yyyy-MM-dd HH:mm:ss
            NOW()：当前时间,yyyy-MM-dd HH:mm:ss
        5.流程函数：
            IF(value,t,f)：如果value为真，则返回t，否则返回f；
            IFNULL(v1,v2)：如果v1不为null，则返回v1，否则返回v2；
            CASE WHEN(表达式) THEN(res1) ELSE(ov) END：如果表达式为true，则返回res1,否则返回ov；
            CASE[表达式] WHEN[value1] THEN[result] ELSE[default] END：如果表达式的值等于value1则返回result，否则返回default；
            流程函数主要用作行转列；
        6.其他函数：
            VERSION()：返回当前数据库版本号；
            DATABASE()：返回当前连接的数据库名；
            USER()：返回当前登录用户名；
            PASSWORD()：返回字符串的密码加密值；
            MD5()：返回字符串的md5加密值；
            INET_ATON(ip)：返回ip地址的数字模式；
            INET_NTOA(num)：返回数字代表的IP；
    
2.关于数据类型：
        整数：
        6位-(支持unsigned);
            TINYINT:1字节，-8位-(支持unsigned);
            SMALLINT:2字节-16位-(支持unsigned);
            MEDIUMINT:3字节-24位-(支持unsigned);
            INT：4字节-32位-(支持unsigned)，
            BIGINT：8字节-64位-(支持unsigned)，
            备注：
                1.整数支持无符号整数，无符号整数最小值从0开始计数；
                2.整数允许设置长度，但是长度仅为显示长度，实际存储数值大小取决于数据类型；
                3.整数允许设置是否自增长，及AUTO_INCREMENT；
        浮点数：
            FLOAT:4字节，32位，精度6位
            DOUBLE:8字节，64位，精度15位
            DECIMAL(M,D):最大取值范围和DOUBLE相同，有效取值范围由M和D决定。M表示总位数，D表示小数位数，D<=M，默认为decimal(10,0)
        位类型：
            BIT(M)：1~8字节，表示范围为：BIT(1)~BIT(64)
        日期时间：
            TIME：表示时间，HH:mm:ss，3字节
            DATE：表示日期，yyyy-MM-dd，3字节
            DATETIME：表示日期时间：yyyy-MM-dd HH:mm:ss，8字节
            TIMESTAMP：表示时间戳，4字节，以整数形式存储，但以yyyy-MM-dd HH:mm:ss格式显示。最大只能表示到2038年
            YEAR：表示年份，yyyy，1901-2155，1字节
        字符串类型：
            CHAR(M)：定长类型，最多存储M个字符，M范围在0~255之间。如果存储字符个数小于M则使用空格填充，如果字符个数大于M则直接截断。
            VARCHAR(M)：变长类型，最多存储M个字符，M范围在0~65535之间。如果存储字符个数小于M，不会填充，如果字符个数超过M则直接截断。
            TINYTEXT(M)/MEDIUMTEXT(M)/TEXT(M)/LONGTEXT(M)：存储文本内容；
            TINYBLOB(M)/MEDIUMBLOB(M)/BLOB(M)/LONGBLOB(M)：存储二进制内容；
        枚举和集合类型：
            ENUM类型：枚举类型
            SET类型：集合类型
    7.关于其他查询：
        1.子查询：
            1.查询中嵌套的查询称为子查询。
            2.子查询的位置可以再select子句、set子句、from子句、where子句中；
            3.子查询用在set子句中必须进行二级嵌套,且只能返回单行单列数据；
        2.联合查询：
            1.联合查询将两个或者多个独立的查询结果集合并为同一个结果集；
            2.联合查询要求多个独立的查询返回的字段个数必须完全相同；
            3.联合查询以第一个独立查询的字段名称作为结果集字段名称；
            4.联合查询有两种联合方式：UNION和UNION ALL：
                UNION：联合两个查询的结果集，并且会用DISTINCT对结果集进行去重，影响性能。
                UNION ALL：仅简单的联合两个查询的结果集，不会使用DISTINCT对结果集进行去重，性能比union要好。
        3.关联查询：
            1.INNER JOIN：条件交叉匹配；
            2.LEFT JOIN：左侧数据全有，右侧数据按条件匹配，有就有，没有就为null；
            3.RIGHT JOIN：右侧数据全有，左侧数据按照条件匹配，有就有，没有就为null；
            4.mysql无外连接，外连接可以通过union联合查询来实现；

3.sql优化措施：
    1.数据表优化：
        1.首先是结构上的设计优化：
            1.先根据业务功能特征设计基本表结构；
            2.其次根据字段在业务中的增删改和查询频率进一步拆分或者合并表结构；
            3.如果有热点数据，可以进一步拆分冷热数据，提高热点数据访问效率；
        2.分表分库方案上的优化：  
            1.提前根据数据的业务特征预估数据增长趋势，确定是否需要水平分表和分表策略；
            2.根据业务的隔离边界确定是否需要分库存储，以及分库的策略，保证热点功能的数据访问效率；
        3.字段数据类型的优化： 
            1.能选整数存储尽量使用整数存储；
            2.能选无符号整数尽量选择使用无符号整数；
            3.在保证存储需求的基础上尽量选择占用空间更小的类型；
            4.尽量避免使用浮点数作为小数的存储类型，必须存储小数时使用decimal作为字段的数据类型。
            5.字符串能使用定长的尽量使用定长的。
            6.字符串必须显式设置长度，长度在保证业务可用的基础上要尽量的短；
            7.TEXT和BLOB尽量避免使用，如果必须使用，尽量单独放在一张表中存储；
            8.IP地址的存储必须转换为32位无符号整数存储；
            9.状态类型的字段使用BIT或者TINYINT存储；
            10.字段在业务上允许的情况下尽量禁止为null；
        4.关于索引的优化：
            1.正确选择添加索引的字段：
                1.innodb必须设置主键索引；
                2.where条件字段必须设置索引；
                3.高频查询内容设置索引；
                4.关联字段设置索引；
                5.排序字段设置索引；
                6.分组字段设置索引；
            2.选择合适的索引：
                1.多个查询条件尽量使用联合索引。
                2.字段内容较长时可以选择使用前缀索引；
                3.优先考虑是否能够用唯一索引。
            3.正确的使用索引：
                1.避免在索引列上进行计算。
                2.避免索引列有显式或者隐式的数据类型转换。
                3.使用联合索引时要遵守最左前缀原则。
        5.存储引擎的选择：
            1.是否需要事务支持；
            2.读写频率如何；
            通常情况下推荐使用innodb引擎；

4.关于索引：
    1.关于索引
        1.索引是在存储数据时额外存储的一部分数据；这部分数据能够对业务数据起到定位的作用，可以提高数据查询效率。
    2.索引作用原理：
        1.索引对数据起着定位的作用，索引文件中存储着索引本身和被索引数据在磁盘的位置，可以通过索引定位到数据的位置；
        2.索引文件中仅仅存储索引本身和被索引数据的磁盘位置，相比数据文件，索引文件要小很多，仅通过几次读取即可查找所有的索引列表，并找到被索引数据的位置，提高数据定位效率；
        3.索引本身很多的情况下，按照顺序存储然后读取同样需要较多的磁盘IO次数，索引数据较小的优势已经比较弱，为了进一步提高索引的读取效率，减少磁盘IO次数，索引文件采用B+tree来映射为文件内容的存储结构，其查找效率可以从O(n)降低到O(logn);
            1.索引文件的所有存储区域被映射为B+tree数据结构，那么索引文件中的内容可以被分为多个块，每一个等同于B+tree结构中的一个节点；
            2.那么从索引文件中查找索引信息，就等同于在B+tree中查找符合要求的节点，可以按照从B+tree数据结构中查找节点的算法来查找，但跟直接从B+tree结构中查找节点不同的是，每查找一个节点就需要从磁盘上读取一块内容，就需要一次磁盘IO；
            3.B+tree数据结构中查找一个节点的方式是从根节点依次向下查找，直至叶子节点，从根节点到叶子节点需要经历的节点数和树的高度相同，那么树的高度即决定了待查找节点的个数，即磁盘的IO次数。而B+tree高度较低，所以很适合作为索引文件的存储结构；
    3.索引文件存储结构的选择：
            选择一种数据结构作为索引文件的存储结构有两个要求：
                1.查找效率高；
                2.复杂度稳定；
            1.线性表结构：
                1.表示文件内容按顺序存储，那么查找文件内容时也需要从头读取；
                2.需要读取整个文件直至文件末尾来查找正确的内容，相当于遍历整个线性表，时间复杂度是O(n)；
                3.效率较低，需要的磁盘IO次数较多；
            2.二叉树：
                1.表示文件内容以二叉树的结构存储，那么查找时以二叉树查找节点的算法查找，时间复杂度为O(logn);
                2.但是一个节点只能有两个子节点，且一个节点只能存储一个元素，导致树的高度会比较高才能容纳要存储的数据，甚至会退化为线性表；
                3.效率较低且不稳定；
            3.红黑树：
                1.和二叉树相同，一个节点只能存储一个元素，且一个节点只能有两个子节点，虽然不会退化为线性表，但是树高度太高，导致需要的磁盘io次数较多；
            4.hash表：
                1.hash表可以直接通过计算hash值确定数据位置，效率最高，但是不支持模糊查找，范围查找，不支持排序操作，不支持分组操作；
    4.mysql中的索引：
        1.正确选择添加索引的字段：
                1.innodb必须设置主键索引；
                2.where条件字段必须设置索引；
                3.高频查询字段设置索引；
                4.关联字段设置索引；
                5.排序字段设置索引；
                6.分组字段设置索引；
        2.选择合适的索引：
            1.多个查询条件尽量使用联合索引。
            2.字段内容较长时可以选择使用前缀索引。
            3.优先考虑是否能够用唯一索引。
        3.正确的使用索引：
            1.避免在索引列上进行计算。
            2.避免索引列有显式或者隐式的数据类型转换。
            3.使用联合索引时要遵守最左前缀原则。
    5.关于B-tree和B+tree：
        1.关于B-tree：
            1.根节点至少有两个子节点；
            2.每一个中间节点中都包含K-1个元素和K个子节点，其中m/2<=k<=m;
            3.每一个叶子节点都包含k-1个元素，其中m/2<=k<=m;
            4.所有叶子节点都位于同一层。
            5.一个节点中的元素从小到大一次排列，且中间节点中的k-1个元素正好是其子节点的区域分隔值；
            6.B-tree中每个元素都是由索引值本身和索引指向的数据地址组成，即B-TREE中查找到索引之后需要再去磁盘中查询数据；    
            7.在B-TREE中只要找到正确的索引，就可以直接根据索引指向的数据地址在磁盘中查找数据，无需遍历整个B-TREE，最差时间复杂度是O(logn)，实际复杂度与key在树种的位置有关。
        2.关于B+TREE：
            1.跟节点至少有两个子节点；
            2.每一个中间节点中都包含K-1个元素和K个子节点，其中m/2<=k<=m;
            3.所有叶子节点都位于同一层；
            4.B+TREE中间节点的元素会在叶子节点上全部存在一份副本，即叶子节点上会存储根节点到叶子节点路径上所有中间节点中的元素。
            5.B+TREE中的中间节点中的元素仅存储索引值本身，只有叶子节点上的元素才会存储索引值及其对应的数据，因此每次查找数据都必须遍历至根节点才能找到索引值对应的数据，时间复杂度固定为O(logn)；
            6.对于主键索引，叶子节点上的元素存储的是索引与整条数据记录，对于非主键索引，叶子节点上存储的是索引与主键值；
            7.而且B+tree叶子节点从左向右两两相连，且已按大小排好顺序，因此支持高效的范围查找和数据排序；
            8.由于B+tree的中间节点不存储数据，仅存储索引值本身，因此单个节点比B-tree可以存储更多的数据。
    6.mysql中的索引：   
        1.Innodb存储引擎：
            1.聚集索引：
                主键索引：
                    1.每个innodb引擎的表都必须要有且只能有一个主键；主键必须唯一，且不能为null；主键尽量保持字段单一，避免使用联合主键；
                    2.如果未设置主键，innodb会自动找将设置了唯一索引，且非空的列作为主键，如果没有这种列，innodb则自己生成一个唯一id列；
                    3.innodb会为主键索引生成一颗B+TREE，且叶子节点上存储的是数据值本身；
                    
            2.非聚集索引：
                1.非聚集索引是指索引绑定的是主键值，而不是索引所在的数据记录行，一个表可以有多个非聚集索引；
                2.每一个非聚集索引都会建立一颗B+TREE，且叶子节点上存储的是主键值；
                3.通过非聚集索引查找数据，如果查找列并非索引列，则需要先从该非聚集索引树查找主键索引值，然后在主键索引树中查找数据。
                4.非聚集索引分为以下几种：
                    从唯一性：唯一索引、非唯一索引
                    从索引字段：单列索引、联合索引、前缀索引
                5.唯一索引和非唯一索引：
                    1.唯一索引是指设置为唯一索引的列中不能包含重复值；
                    2.非唯一索引是指设置为非唯一索引的列中可以包含重复值；
                6.单列索引和联合索引：
                    单列索引：索引列只是一个字段；
                    联合索引：1.索引列是多个字段联合起来作为一个索引；
                             2.联合索引的设置有顺序要求，必须符合最左前缀原则。
            3.覆盖索引：
                1.覆盖索引并非索引，仅仅只表示索引字段包含了待查字段，在查询该字段时，无需回表，在索引中即可获取到值，查询效率较高。
5.事务：
    1.关于事务：
        1.事物就是一个最小的sql执行单元，这个执行单元由一个或者多个sql组成，能够保证sql操作和执行结果的一致性；
    2.事务特性：
        1.事务核心的特性是一致性，即操作和结果的一致，如果操作执行成功，那么结果也应该得到修改，如果操作执行失败，那么结果应该恢复原值；
        2.事务的一致性则通过另外三个特性来保证：原子性、隔离性、持久性；这四个特性共同被称为ACID特性:
            A：Atomic：原子性：
                1.指组成事务的一组操作要么全部成功、要么全部失败。
                2.这块的原子性和编程中的原子性意义有所不同：
                    编程中的原子性：
                      1.编程中的原子性是指当前执行的一组操作是一个最小的执行单元，强调的是操作本身的不可分割性，但并不关心操作成功或者失败对结果带来的影响。
                      2.即当前线程执行同步操作期间其他线程不能介入，必须等当前线程执行完成之后其他线程才能执行；但是即使当前线程执行期间发生失败，那么已经执行过的指令也已成为事实；
                    事务中的原子性：
                      1.事务中的原子性是指操作和最终结果之间的原子性，强调的是操作和数据变化要一致，但并不关心当前事务执行期间是否有其他事务在执行；
                      2.即：一个事务执行期间，也允许其他事务同时执行，但如果一组操作中部分成功，部分失败，那么就需要把已经成功的操作对数据的改变恢复原值；
                3.原子性的实现方式：
                    事务如果全部执行成功，那么自然而然符合原子性；但如果事务部分成功部分失败，为了满足原子性，就需要把已经执行成功的数据变更结果进行回滚；所以为了保证原子性，只需要能够回滚已经变更的数据即可；
                    innodb中则通过undo log反向记录已经执行成功的操作，然后在需要回滚的时候执行这些反向操作即可实现数据回滚。
            C：Consistency：一致性；
                事务中的一致性是指操作和结果的一致，即操作成功，结果也必须被更新，操作失败，结果也必须回退；一致性是目的，需要通过原子性、隔离性、持久性来保证。
            I：Isolation：隔离性：
                1.隔离性是指对同时运行的事务进行隔离，是为了防止事务并发执行时造成数据的不一致；目的也是为了保证事务操作和结果的一致，只是解决的问题不同；
                2.隔离性的必要性：
                    1.由于当前事务执行期间，其他事务也可以同时执行，如果事务之间没有做任何隔离，那么当前事务就会读取到其他事务对数据的更新结果，如果当前事务基于其他事务的更新结果来执行后续操作，可能会导致错误的结果，所以必须对事务进行隔离；
                3.隔离的类型：
                    1.当前事务是否能够看到其他未提交事务的更新结果；
                    2.当前事务是否能够看到其他已提交事务更新的结果；
                    3.事务之间是否需要按顺序串行执行；
                    根据上述隔离方式的不同，innodb提供了四种不同的隔离级别；
            D：Duration：持久性；
                1.持久性是指事务执行完成之后，对数据做出的变更必须持久的存储在磁盘上；主要强调的是客户端响应结果和服务端执行结果的一致；
                2.持久性主要解决的问题是服务端响应给客户端已经修改成功，但是却由于服务端崩溃等其他原因导致数据未落库，客户端再次查询时却查到旧的数据。
                3.持久性主要通过redo log和binlog来实现。
    3.事务类型：
        1.扁平事务：
            1.扁平事务是指组成一个事务的所有操作都在同一个层面，由BEGIN开始，由ROLLBACK或者COMMIT结束，在BEGIN和ROLLBACK/COMMIT之间的操作要么全部成功，要么全部失败；扁平事务是最常用的本地事务类型；
            2.扁平事务的编程方式：
                #关闭自动提交-开启事务
                SET AUTOCOMMIT = 0;

                #执行sql
                INSERT INTO test(name,age) VALUES('tom',23);

                #提交或者回滚事务
                COMMIT; 提交事务
                ROLLBACK;回滚事务

        2.带保存点的扁平事务：
            1.此类事务本质上仍然是扁平事务，但是可以设置保存点，在回退时可以指定回退到哪一个保存点；但是回退到指定保存点之后事务并未结束，只是表示当前事务处于指定的保存点而已，要想结束事务还需要使用COMMIT或者ROLLBACK回滚整个事务；
            2.带保存点的扁平事务：
                #关闭自动提交-开启事务
                SET AUTOCOMMIT = 0;

                #执行sql1
                INSERT INTO test(name,age) VALUES('tom',23);

                #设置保存点1
                SAVEPOINT 1;

                #执行sql2
                INSERT INTO test(name,age) VALUES('tom',23);

                #设置保存点2
                SAVEPOINT 2;

                #回滚到保存点1，此时事务中的sql2将会被回退，但是sql1并不会，而且当前事务也并未结束；需要继续使用COMMIT提交事务或者使用ROLLBACK回退事务；
                ROLLBACK TO 1;

                #提交或者回滚事务
                COMMIT; 提交事务
                ROLLBACK;回滚事务
        3.链式事务：
            事务与事务之间链式执行，类似于带有保存点的扁平事务；
        4.嵌套事务：
            由多层事务嵌套而成，顶层事务起着决定性作用；
        5.分布式事务：
            分布式环境下的扁平事务
    4.事务隔离级别：
        1.按照事务之间不同的隔离程度可以分为四种不同的隔离级别：
            READ UNCOMMITTED   读未提交(RU)
            READ COMMITTED     读已提交(RC)
            REPEATABLE READ    可重复读(RR)
            SERIALIZABLE       串行化执行(SER)
        2.不同隔离级别下事务的特征：   
            1.READ UNCOMMITTED隔离级别下：要求当前事务运行期间每次查询总能看到最新未提交的事务对数据的修改；但是容易出现脏读的问题，事务执行效率最高；
            2.READ COMMITTED隔离级别下：要求当前事务运行期间不能看到其他未提交事务对数据的修改，但是每次查询操作都能看到最新一个已提交事务对数据的修改；该要求下可以避免脏读问题，但是会出现不可重复读的问题，效率次之；
            3.REPEATABLE READ隔离级别下：要求当前事务既不能看到当前事物运行期间其他未提交事务对数据的修改，也不能看到其他最新已提交事务对数据的修改；事务运行期间多次执行相同的查询操作必须得到相同的结果；理论上按照该要求，在RR隔离级别下不会再出现不可重复读的问题，但是会出现幻读问题。效率次之；
            4.SERIALIZABLE隔离级别下： 要求事务与事务完全串行化执行，一个事务必须等待另一个事务提交之后才能开始；理论上可以完全避免所有问题，效率较低；
        3.关于不同隔离级别的选择：
            1.除过SERIALIZABLE隔离级别以外，其余三个隔离级别下事务并发执行时均有不同的问题，但对应的问题都只会在对应的业务场景下存在，因此合适的业务场景下也是可以选用的；
            2.由于innodb引擎采用锁+mvcc机制共同实现事务的隔离级别，因此在RR隔离级别下，加锁时采用next-key lock加锁方式，会加上间隙锁，如果事务中采用的是当前读，当前读会加上间隙锁，新增语句不会执行成功，因此不会出现幻读现象，如果使用的是快照读，那么会出现幻读现象；
            3.解决不同隔离级别下的问题需要将隔离级别进行升级，即：
                RC隔离级别即可避免脏读问题；
                RR隔离级别即可避免不可重复读和脏读问题；
                SER隔离级别即可避免脏读、不可重复读、幻读问题；
                但是有两种更新丢失问题需要进行关注：
            第一种更新丢失问题如下：
            场景1：
                事务1                                                           事务2
                begin;                                                          begin;
                #将类型为1的用户改为类型2
                UPDATE user SET user_type = 2 WHERE user_type = 1;
                                                                                #将类型为1的用户改为类型3
                                                                                UPDATE user SET user_type = 3 WHERE user_type = 1;
                #提交
                commit;
                                                                                #提交
                                                                                commit
            上述这种场景，在理论上是会发生，但实际上在当前mysql中，任意一个隔离级别下都不会发生，因为update操作会以Record lock或者next-key lock加锁，事务1未提交之前事务2会阻塞等待。
            
            第二种更新丢失：对于下面两种逻辑上的更新丢失问题，却在任意一种隔离级别下都无法完全避免，场景如下：
            场景1：
                事务1                                                           事务2
                begin;                                                          begin;
                #读取用户金额:假设money=10
                SELECT money FROM user WHERE uid = 1;
                                                                                #读取用户金额:假设money=10
                                                                                SELECT money FROM user WHERE uid = 1;
                #将用户金额加10
                UPDATE user SET money = 10+10 WHERE uid = 1;
                                                                                #将用户金额加10
                                                                                UPDATE user SET money = 10+10 WHERE uid = 1;
                #提交
                commit;
                                                                                #提交
                                                                                commit
                此时，事务2会覆盖掉事务1对金额作出的修改；导致事务1对金额的更新丢失；

            场景2：
                事务1                                                           事务2
                begin;                                                          begin;
                #读取用户金额:假设money=10
                SELECT money FROM user WHERE uid = 1;
                                                                                #读取用户金额:假设money=10
                                                                                SELECT money FROM user WHERE uid = 1;
                #将用户金额加10
                UPDATE user SET money = 10+10 WHERE uid = 1;
                                                                                #将用户金额加10
                                                                                UPDATE user SET money = 10+10 WHERE uid = 1;
                                                                                #提交
                                                                                commit
                #提交
                commit;
                                                                                
                此时，事务1会覆盖掉事务2对金额作出的修改；导致事务2对金额的更新丢失；
                这种场景的核心就在于后续的更新操作需要基于前一步查询操作的查询结果，但是在四种隔离级别下，由于执行的是快照读，因此第一步都会读取到相同的数值，最终导致其中一个事务的更新被覆盖；对于这种更新丢失可以通过以下两种方式避免：
            1.通过手动加排他锁，阻塞第一步的查询操作：
                select ... for update;
            2.通过将查询更新操作合二为一作为原子操作执行，阻塞更新操作：
                UPDATE user SET money = money+10 WHERE uid = 1;
            3.如果上述操作是-10,对于金融数据不能为负数，所以只能用第一种方案，在查询和更新之间加上业务逻辑解决；

        4.innodb默认隔离级别：
            1.innodb默认隔离级别是RR级别，原因和MySQL版本对应的主从同步机制以及innodb在不同隔离级别下加锁方式有关，有主从不一致的风险。具体如下：
                1.在RC和RU隔离级别，innodb没有采用next-key lock这种加锁方式(使用的是record lock这种加锁方式)，那么以下场景会执行成功：
                      场景1：
                        事务1                                                           事务2
                                                                                        
                        begin;                                                          begin;
                        #删除类型为5的所有用户
                        DELETE FROM user WHERE utype < 5;
                                                                                        #增加一个utype=4的用户
                                                                                        INSERT INTO user(utype,uname) VALUES(4,'tom');
                                                                                        #提交
                                                                                        commit
                        #提交
                        commit;
                    最终，master里面会存在一个utype=4的数据；
                2.而在mysql低版本之前,binlog采用的是statement格式，这种格式会按照commit指令提交顺序记录更新操作的sql；那么在实际的binlog中是先增加后删除，因此在将该binlog同步至slave中时会导致从库中没有utype=4的用户，会存在主从不一致的问题；但是row格式的话不会存在这个问题，因为row格式记录的是主库中的数据值本身；
                3.mysql5.7.7之前默认是statement，但是已经开始支持其他两种格式，在mysql5.7.7以后默认为row格式；
                4.statement会以明文的方式记录执行过的sql，追加sql的模式记录数据，磁盘文件小，而row则直接记录最终的数据本身，准确性高，但是记录数据较多，磁盘io相对较高，性能较低；
        5.不同隔离级别的具体实现方式：
            1.READ UNCOMMITTED隔离级别下：
                仅通过锁机制来实现，加锁时以Record lock方式加锁；
            2.READ COMMITTED隔离级别下：
                通过锁和MVCC共同实现，加锁时以Record lock方式加锁；
            3.REPEATABLE READ隔离级别下：
                通过锁和MVCC共同实现，加锁时以next-key lock方式加锁；
            4.SERIALIZABLE隔离级别下：
                仅通过锁机制实现，加锁时以next-key lock方式加锁；
        
    5.事务隔离级别的实现方式-锁：
        1.锁是innodb实现事务间隔离的主要方式，用来解决不同事务间读写、写写之间的冲突。
        2.锁的分类：
            1.按照原理不同：读锁(共享锁)、写锁(排他锁)；
            2.按照加锁力度不同：行锁、表锁；
        3.关于行锁：
            1.行锁是指，加锁时以数据行的索引为单位加锁；
            2.行锁按照类型不同分为共享锁和排他锁：
                共享锁：表示加上该锁的事务可以读取一行记录；
                排他锁：表示加上该锁的事务可以删除或者更新一行记录；
            3.为了保证事务并发执行时的数据安全，共享锁和排他锁有不同的兼容性，具体如下：
                        X         S 
                X       0         0
                
                S       0         1
                兼容性说明：
                    1.0表示两种锁互不兼容，1表示两种锁互相兼容；
                    2.多个事务不能同时持有互不兼容的锁，但是可以同时持有互相兼容的锁；
                    3.多个事务添加互不兼容的锁时会造成阻塞等待，如果事务之间互相等待对方持有的锁会造成死锁；
        4.关于意向锁：

        5.关于加锁方式：
            Record Lock:
                1.表示行锁，即以单条数据记录为单位对数据加锁；
                2.Innodb的锁基于索引实现，因此行锁实际上锁住的索引树上的索引；
                3.在RU和RC隔离级别下采用的是这种方式。
            Gap Lock:
                1.间隙锁，即对查询条件中的数据间隙加锁；所谓条件间隙是指当前条件范围内，数据库中实际存在的数据记录之间的间隙；
                2.间隙锁只包括条件间隙，并不包括数据库中符合条件且实际存在的数据记录，符合条件的记录本身并未加锁；
            Next-Key Lock:
                1.Record Lock和Gap Lock互相结合的一种加锁方式；即锁定条件间隙也锁定数据记录本身；
                2.在RR隔离级别和SERIALIZABLE隔离级别下采用的就是这种加锁方式；
        
        6.不同sql下加锁分析：
            1.加锁方式和范围相关因素：
                1.隔离级别：RU、RC、RR、SERIALIZABLE
                2.sql类型：SELECT、SELECT...FOR UPDATE、SELECT...LOCK IN SHARE MODE、UPDATE、DELETE
                3.条件列类型：是否聚集索引列、是否非聚集索引列、是否非索引列
                4.条件类型：精确查询、范围查询
            2.不同sql下加锁细节：
                1.SELECT操作：
                    1.RU隔离级别：
                        条件类型：任意
                        条件列索引类型：任意
                        *以Record lock方式加共享锁、并且读完立即释放锁；
                    2.RC/RR隔离级别：
                        条件类型：任意
                        条件列索引类型：任意
                        *通过MVCC实现，无需加锁，支持读写并发；
                    3.SERIALIZABLE隔离级别：
                        条件类型：任意
                        条件列索引类型：任意
                        *以Next-Key Lock的方式加共享锁；
                2.SELECT...FOR UPDATE/SELECT...LOCK IN SHARE MODE/DELETE/UPDATE
                    1.RU隔离级别：
                        条件类型：任意
                        条件列为聚集索引/唯一索引：对符合条件的聚集索引以Record lock方式加锁；
                        条件列为非聚集索引：对符合条件的非聚集索引和聚集索引以Record lock方式同时加锁；
                        条件列为非索引：会全表扫描，在扫描过程中会对每一行记录的聚集索引以Record lock方式加锁，然后检测是否符合条件，若不符合条件立即释放锁；最终只对符合条件的数据行加索引；
                    2.RC隔离级别：
                        条件类型：任意
                        条件列为聚集索引/唯一索引：对符合条件的聚集索引以Record lock方式加锁；
                        条件列为非聚集索引：对符合条件的非聚集索引和聚集索引以Record lock方式同时加锁；
                        条件列为非索引：会全表扫描，在扫描过程中会对每一行记录的聚集索引以Record lock方式加锁，然后检测是否符合条件，若不符合条件立即释放锁；最终只对符合条件的数据行加索引；
                    3.RR隔离级别：
                        条件类型：精确查询；
                            条件列为聚集索引/唯一索引：对符合条件的聚集索引以Record lock方式加锁；
                            条件列为非聚集索引：对符合条件的非聚集索引以Next-key lock方式加读锁或者写锁和聚集索引加读锁；并在条件列已存在的数值两侧加间隙锁；
                            条件列为非索引：通过Next-Key Lock的方式加锁，记录本身上加行锁，全表间隙加Gap Lock；
                        范围查询：
                            条件列聚集索引：通过Next-Key Lock的方式加锁；条件范围内的数据记录本身加行锁，条件间隙加Gap Lock，匹配到的数值外侧Gap lock;
                            条件列非聚集索引：通过Next-Key Lock的方式加锁；条件范围内的数据记录本身加行锁，条件间隙加Gap Lock,匹配到的数值外侧Gap lock;
                            条件列非索引：会通过Next-Key Lock的方式加锁；记录本上加行锁，全表间隙加Gap Lock；
                    4.SER隔离级别：
                        条件类型：精确查询；
                            条件列为聚集索引/唯一索引：对符合条件的聚集索引以Record lock方式加锁；
                            条件列为非聚集索引：对符合条件的非聚集索引以Next-key lock方式加读锁或者写锁和聚集索引加读锁；并在条件列已存在的数值两侧加间隙锁；
                            条件列为非索引：通过Next-Key Lock的方式加锁，记录本身上加行锁，全表间隙加Gap Lock；
                        范围查询：
                            条件列聚集索引：通过Next-Key Lock的方式加锁；条件范围内的数据记录本身加行锁，条件间隙加Gap Lock;
                            条件列非聚集索引：通过Next-Key Lock的方式加锁；条件范围内的数据记录本身加行锁，条件间隙加Gap Lock;
                            条件列非索引：会通过Next-Key Lock的方式加锁；记录本上加行锁，全表间隙加Gap Lock；
        7.关于死锁：
            1.死锁：两个事务互相等待对方持有的锁，造成两个事物都处于阻塞等待而无法继续向下执行的状态称之为死锁。
            2.造成死锁的场景最常见的就是：加锁顺序不一致！
            3.避免死锁的核心方式：1.保证加锁顺序一致；2，一次性锁定当前事务需要访问的所有数据记录；
            2. 解决死锁：通常情况下有三种方式：
                1.立即回滚：一旦发生阻塞等待，立即回滚当前事务；此种方式代价太大，如果竞争严重的话可能导致事务都无法正常向下执行，并且高权重的事务回滚代价太大；
                2.超时回滚：一旦发生阻塞等待，设置超时时间(innodb中通过innodb_lock_wait_timeout设置超时时间)，等待时长超过超时时间之后立刻回滚！但是超时回滚无法确定事务权重，如果事务本身权重很高，回滚代价会比较大；
                3.死锁检测：innodb还实现了wait-for-graph(等待图)的方式进行死锁检测；等待图需要数据库保存以下两种信息：1.锁的信息链表、2.事务等待链表；在Innodb1.0版本之后，Innodb在INFORMATION_SCHEMA架构下添加了INNODB_TRX、INNODB_LOCKS、INNODB_LOCKS_WAITS三张表；其中INNODB_TRX存储着事务的执行概况，其中INNODB_LOCKS存储着锁争用的概况，INNODB_LOCKS_WAITS中存储着事务与其等到的锁的情况；通过上述三个表即可获取到锁的信息链表和事务等待链表！         
            3. 关于INNODB_TRX、INNODB_LOCKS、INNODB_LOCKS_WAITS
                1.INNODB_TRX:
                    trx_id：事务唯一id
                    trx_state：当前事务状态
                    trx_started：事务开始时间
                    trx_requested_lock_id：等待事务的锁id，如果事务的trx_state为LOCK WAIT时，那么该值就表示当前事务等待之前事务占用锁的id，如果trx_state的值不为LOCK WAIT，那么该字段为null；
                    trx_wait_started：事务等待开始的时间；
                    trx_weight：事务的权重，当发生死锁时，系统会根据该值选择权重最小的事务回滚；
                    trx_mysql_thread_id：mysql中的线程id；
                    trx_query：事务运行的sql语句；
                    通过INNODB_TRX表可以查询当前有哪些事务正在运行，事务的运行状态如何，事务当前运行的sql语句等详细信息；
                2. INNODB_LOCKS：
                    lock_id：锁的id
                    lock_trx_id：事务的id
                    lock_mode：锁的模式
                    lock_type：锁的类型、表锁还是行锁
                    lock_table：要加锁的表
                    lock_index：锁住的索引
                    lock_space：锁对象的space_id
                    lock_page：事务锁定页的数量，若是表锁
                    trx_state：当前事务状态
                    trx_started：事务开始时间
                    trx_requested_lock_id：等待事务的锁id，如果事务的trx_state为LOCK WAIT时，那么该值就表示当前事务等待之前事务占用锁的id，如果trx_state的值不为LOCK WAIT，那么该字段为null；
                    trx_wait_started：事务等待开始的时间；
                    trx_weight：事务的权重，当发生死锁时，系统会根据该值选择权重最小的事务回滚；
                    trx_mysql_thread_id：mysql中的线程id；
                    trx_query：事务运行的sql语句；
                
                    通过INNODB_TRX表可以查询当前有哪些事务正在运行，事务的运行状态如何，事务当前运行的sql语句等详细信息；
                3.INNODB_LOCKS_WAITS：
                    requesting_trx_id：申请锁的事务id
                    requesting_lock_id：申请锁的事务申请的锁id
                    blocking_trc_id：阻塞的事务id，即当前占有锁的事务id
                    blocking_lock_id：阻塞事务占有的锁id；
                    在该表中，可以查看当前数据库中哪些事务在等待锁，等待锁的id以及占有该锁的事务id信息，方便查看导致死锁的情况；
        8.对于死锁的排查一般有两种方式：
            1.查看死锁日志：
                方式：show engine innodb status；
                结果：上述sql执行完成之后，有一个TRANSACTIONS项，会打印等待锁的sql；
            2.手动查看innodb_trx、innodb_locks、innodb_locks_waits表，手动分析死锁情况；
        
        9.自增长列与锁：
            1.Innodb存储引擎内的自增长列有一个自增长计数器，在插入数据时，自增长列的数值是通过查询该自增长计数器的最大值，并在当前最大值基础上加1得到最新的数值；为了能够保证在事务并发执行下能够得到正确的计数器数值，在查询计数器数值时会加锁查询：select MAX(auto_inc_col) FROM t FOR UPDATE；但是该查询加的锁并不是等事务结束之后才释放的，而是在最新数值插入自增长列之后会立即释放，目的在于保证自增长列的插入性能，这种机制称为AUTO-INC Locking；
            2.对于AUTO-INC Locking机制而言会有两个问题：
                1.自增长列在有事务混滚时可能造成自增长列断层，自增长列的值会不连续；
                2.由于自增长列也要加锁，在大批量插入时，需要阻塞等待自增长列值计算结果，因此性能同样较差；
            3.在mysql5.1.2版本以上，提供了一种轻量级互斥量自增长机制，可以大大提高自增长列的插入性能；mysql中一共有三种模式来获取自增长列的值，并提供了一个参数来选择使用何种模式：innodb_autoinc_lock_mode，有三个值可取：0、1、2，默认是1，但是也可根据不同的插入类型选择不同的模式；
            4.mysql中按照插入类型不同，分为以下几类：
                1.insert-like：指所有的插入语句，如：INSERT、REPLACE、INSERT...SELECT、REPLACE...SELECT、LOAD DATA;
                2.simple-inserts：指在插入之前就能确定要插入的条数，如：INSERT、REPLACE；但是不包括INSERT ...ON DUPLICATE KEY UPDATE语句；
                3.bulk-inserts：在实际插入之前无法确定要插入的条数，如：INSERT...SELECT、REPLACE...SELECT、LOAD DATA;
                4.mixed-mode inserts：指在插入时，一部分值是确定的，一部分值时自增长的，包括INSERT ...ON DUPLICATE KEY UPDATE语句；
            5.innodb_autoinc_lock_mode参数在取0时，任何插入类型都采用AUTO-INC Locking的方式；在取1时，对于simple inserts采用轻量级互斥量的方式实现，对于bulk inserts采用AUTO-INC Locking的方式实现；取2时，无论何种插入类型，都采用轻量级互斥量的方式实现；默认情况下取1；
            6.对于myisam引擎和innodb引擎不同，myisam存储引擎在插入数据时会添加表锁，无需考虑并发插入的问题；
        10.关于乐观锁和悲观锁：
            数据库默认加锁都是悲观锁；乐观锁需要手动增减版本记录字段实现；
            
    6.事务的隔离实现方式-MVCC:
        1.关于MVCC：
            1.关于MVCC，即Multi Version Concurrency Control，多版本并发控制，通过带有事务id的数据记录的版本链结合快照来实现数据读取的一种机制；
            2.MVCC出现的原因：解决读写冲突的传统方式是加锁，但是加锁会导致读写无法同时执行，读写并发执行时效率较低；而在MVCC机制下，数据更新直接更新数据表中的字段值，而数据读取，则读取的是数据的历史版本，因此读写不冲突，提高了读写并发执行的效率；
            3.MVCC作用：以无锁的方式解决读写并发执行时的冲突问题。
        2.MVCC工作原理：
             1.MVCC机制需要借助带有事务id的数据记录的版本链和快照来实现，通过版本链来记录数据的不同版本，通过快照信息来确定版本链中当前事务可见且最新的数据版本；
             2.在事务修改数据之前，会先记录数据修改之前的数据版本和当前事务id到undo log中，并在数据表中记录当前数据版本的位置，形成一个数据版本链。
             3.一个事务查询数据时，会先创建当前数据的事务快照信息，记录当前活跃的事务id以及最后一次更新待查询数据的事务id，通过比对当前事务id和数据库中活跃的数据id来确认该数据对于当前事务可见且最新的版本并返回。
        3.MVCC实现原理：
            1.实现MVCC需要两个机制参与：1.带有事务id的数据版本链；2.数据快照。
            2.关于带有事务id的数据版本链：
                1.功能：记录数据的不同版本内容，提供查询时的数据来源。
                2.实现原理：
                    1.通过undo log记录不同版本的数据内容：
                     undo log包括两种类型：
                        1.insert undolog：
                            表示当前事务中执行的insert操作记录；
                            insert undolog只有对于保持事务的原子性有用，用来在事务的后续操作执行失败时进行回滚；事务提交之后会立即删掉；

                        2.update undolog;
                            表示事务中执行的update和delete操作记录；
                            update undolog对于保持事务原子性和实现MVCC均有用到；因此事务完成之后不会立即丢弃，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除
                            update undolog在MVCC中的作用就是存储数据的上个版本信息，
                    2.通过数据库的字段记录上个版本数据的位置，链接各个数据版本：
                        1.三个隐藏字段：
                        DB_TRX_ID：
                            最后一次修改数据记录的事务id；记录当前数据最后一次是被哪个事务修改的；
                            事务id在开启事务时产生，全局唯一，趋势递增；

                        DB_ROLL_PTR：
                            指向该数据记录上一个版本的指针，通过该指针即可查看上一个版本的数据信息；
                            版本之间通过该字段连接起来，形成版本链；

                        DB_DEL_BIT：表示该数据的更新操作是删除操作；

                        实际上，如果表中没有主键，innodb还会主动添加一个DB_ROW_ID的隐藏字段，作为当前表的主键；
                    3.隐藏字段和undolog配合实现版本链的方式:
                        删除、更新一条数据时具体流程如下：
                            1.先将数据加锁，然后将当前数据复制一份存储在undolog中，那么undolog中的这份旧数据就是当前数据的上一个版本；
                            2.之后将数据表中的数据更新为新的数据内容，然后将数据记录行中的DB_TRX_ID更新为当前事务id，DB_ROLL_PTR指向undolog中旧数据的地址；
                        数据表中数据更新之后的DB_ROLL_PTR的字段指向undolog中的旧数据；而undolog中的旧数据也有DB_ROLL_PTR字段，指向该旧数据的上一个版本，依次类推，就形成了该数据的一个版本链，通过DB_ROLL_PTR即可追溯到该数据的每一个版本；
            3.数据快照：
                1.快照作用：
                    快照用来在数据记录版本链中选择当前事务可见且最新的数据版本； 
                2.快照的使用：
                    只有普通的select查询操作才会使用MVCC机制，即只有普通的select查询才会通过快照从数据记录版本链中读取数据，其余类型的操作均使用加锁的方式从数据表中读取实时数据；
                3.快照的创建时机：
                    1.快照创建时机之和发起select读的时机有关，和开启事务的时机无关；
                    2.对于RC隔离级别，每次发起select读都会新创建快照；对于RR隔离级别，只有首次发起select读才会创建快照；
                4.快照确定不同版本数据对当前事务可见性的方式：
                    1.在创建快照的一刻起，会保存当前数据库中所有的活跃事务id，并记录最小的活跃事务id(up_limit_id)和下一个即将分配的事务id(当前事务id最大值+1,low_limit_id);
                    2.获取数据表中当前数据的DB_TRX_ID，该DB_TRX_ID值是该数据记录最后一次被修改时的事务id，但是DB_TRX_ID表示的事务有可能已经提交，也有可能未提交；因此需要和当前活跃id列表进行比较：
                        1.如果DB_TRX_ID<up_limit_id：说明在创建该快照的那一刻之前，最后一次修改该记录的事务已经提交，那么数据表中该数据对当前事务可见，而且在MVCC机制中，数据表中的数据总是最新的版本，因此符合可见且最新的数据版本要求，那么将该数据返回给当前事务即可；
                        2.如果：up_limit_id<=DB_TRX_ID<low_limit_id，那么说明当前数据版本对应的事务还未提交，那么还需要判断DB_TRX_ID是否等于当前事务id:
                            1.如果DB_TRX_ID等于当前事务id，那么说明最后一次修改该数据的事务就是当前事务，那么该数据同样对当前事务可见；
                            2.如果不同，那么说明最后一次对该数据修改的事务不是当前事务，并且当前事务还未提交，那么当前数据版本对当前事务不可见，需要根据当前数据的DB_ROLL_PTR指针从undolog中查找上一个数据版本，然后继续按照上述逻辑比较；            
        4.关于快照读和当前读：
            1.快照读是指在读取时创建事务快照信息，并根据快照信息从数据历史版本链中查找数据的方式；只有普通的select查询才是快照读；
            2.当前读是指在读取数据时会先对数据表中的数据加锁，加锁成功后从数据表中读取实时数据；update/delete/select...for update/select...lock in share mode都是当前读；
            3.当前读和快照读是只在RC和RR隔离级别下存在的概念，因为只有RC和RR隔离级别下才使用了MVCC机制；
        
        5.MVCC只作用在RC和RR隔离级别的原因：
            MVCC只作用在RC和RR隔离级别下作用，解决读写之间的冲突，RU和SERIALIZABLE隔离级别并不会使用MVCC；原因如下：
            1.由于RU隔离级别要求当前正在运行中的事务能够读取到最新未提交事务对数据的修改结果，而MVCC是通过数据的版本链来实现的，只有事务提交之后当前数据才会增加一个版本记录，事务提交之前并不会产生新的版本记录，无法满足RU隔离级别对于数据读取的要求，因此MVCC并不适用于RU隔离级别；
            2.由于使用MVCC时，在快照读操作下会有幻读的问题，并不符合SERIALIZABLE隔离级别的要求，因此在该级别下也不适用MVCC；
        
        6.MVCC实现RC和RR隔离级别要求的原因：
            1.快照读的结果和事务之间开启的先后顺序没有关系，只取决于在事务中第一次执行快照读的时机；比如事务1开启早于事务2，事务2中对数据做出修改，如果在事务1执行快照读之前，事务2已经commit，那么事务1执行快照读是可以读取到事务2的修改结果的；
            2.在RC隔离级别下，每次执行快照读时都会新创建快照，因此在RC隔离级别下，当事务中执行快照读总是可以看到最新已提交事务对数据做出的修改，符合RC隔离级别的要求；
            3.在RR隔离级别下，只有第一次执行快照读时才会创建快照，此后在执行快照读时，总是使用第一次创建的快照，因此在RR隔离级别下，多次执行相同的快照读看到的一定是同一个版本的数据，可以避免出现不可重复读的现象，符合RR隔离级别的要求；
            4.但是需要注意的是：在RR隔离级别下，如果先使用快照读查找数据，那么此时其他事务仍然可以对该数据修改，如果其他事务修改完成之后提交，再在当前事务中使用当前读的SELECT查找数据时仍然无法避免不可重复读的问题；除非一值使用快照读或者一直使用当前读或者先使用当前读后使用快照读；(RR隔离级别下无法完全避免幻读问题，其原因相同)；  
    
6.关于存储引擎

7.关于日志
    1.查询日志作用:
        1.查询日志用来记录执行过的sql语句；
        2.查询日志分为一般查询日志和慢查询日志，如果sql执行时长没有超过query_long_time变量设置的时长就记录到一般查询日志，否则记录到慢查询日志；
    2.关于一般查询日志：
        1.作用：
            一般查询日志用来记录执行过的每一条sql；
        2.启用状态：
            1.默认处于关闭状态，线上也不推荐开启，否则影响sql整体执行效率；
            2.可以在配置文件中通过--general_log=[1|0]开启或者关闭；
        3.存放路径：
            1.默认在数据源目录下，名称为数据库实例名称.log;
            2.可以在配置文件中通过--general_log_file=file_name设置存放路径；
        4.和一般查询日志相关的变量:
            general_log=off # 是否启用一般查询日志，为全局变量，必须在global上修改，默认是off，设置为1即启用。
            sql_log_off=off # 在session级别控制是否启用一般查询日志，默认为off，设置为1即启用
            general_log_file=/mydata/data/hostname.log  # 默认是库文件路径下主机名加上.log

    3.关于慢查询日志:
        1.作用:
            记录执行时长过长的sql语句，辅助sql优化；
        2.关于慢查询：
            1.如果一条sql的执行时长超过long_query_time设置的时间，会认为该sql是一条慢查询语句，判断标准仅仅只是sql实际执行耗时，并不包括sql等待锁的耗时；
            2.慢查询日志是在查询结束释放锁之后才开始记录的，因此慢查询日志中的sql和实际执行的sql顺序可能会不同；
        3.开启状态:
            1.慢查询日志默认是关闭状态；
            2.在配置文件中可以通过slow_query_log=1老开启；
        4.存放路径:
            1.如果开启了慢查询，其日志路径默认在数据源目录下，以主机名-slow.log为名；
            2.也可以在配置文件中通过slow_query_log_file配置慢查询日志存放路径；
        5.慢查询限时:
            1.默认是10s钟；
            2.可以在配置文件中通过设置long_query_time来设置慢查询限时，在mysql5.1之后已经支持微秒级的慢查询过滤；
        6.和慢查询相关的变量:
            long_query_time=10 # 指定慢查询超时时长(默认10秒)，超出此时长的属于慢查询
            log_output={TABLE|FILE|NONE} # 定义一般查询日志和慢查询日志的输出格式，默认为file，如果指定为NONE，那么即便开启慢查询也不会记录日志；
            log_slow_queries={yes|no}    # 是否启用慢查询日志，默认不启用
            slow_query_log={1|ON|0|OFF}  # 也是是否启用慢查询日志，此变量和log_slow_queries修改一个另一个同时变化
            slow_query_log_file=/mydata/data/hostname-slow.log  #默认路径为库文件目录下主机名加上-slow.log
            log_queries_not_using_indexes=OFF # 查询没有使用索引的时候是否也记入慢查询日志
        7.慢查询日志格式:
            1.慢查询日志非二进制格式，以文本形式记录慢查询内容，可以直接打开查看；
            2.也可以通过mysql提供的mysqldumpslow工具查看;
    4.关于错误日志：
        1.错误日志作用：
            1.记录mysql在启动和关闭时的所有信息，包括错误或者正确的信息；
            2.记录mysql在运行期间遇到的错误信息；
        2.错误日志开启状态:
            错误日志默认处于开启状态，不能关闭
        3.错误日志路径：
            1.错误日志路径默认在数据源目录下，名称为主机名称.err；
            2.在配置文件中可以通过--log-error指定错误日志路径；
        4.和错误日志相关的变量:
            log_error：可以通过show variables like '%log_error%'查看mysql错误日志路径;
    5.关于二进制日志：
        1.二进制日志(bin log)作用:
    二进制日志中记录了可能引起数据库改变的事件信息，包括可能引起数据库本身改变或者数据改变的事件信息,不会包括类似select或者show这种查询语句；
    2.二进制日志启用状态：
        1.默认不启用；
        2.可以通过在配置文件中添加--log-bin=[on|off|file_name]选项来开启；
        3.生产环境建议开启；
    3.二进制日志路径：
        1.默认在数据源目录下，以主机名-bin.000001为名，后缀数字逐渐增长；
        2.也可以通过--log-bin=file_name来启用并设置二进制日志路径；生产环境建议不要使用默认路径，并定时备份binlog;
    4.二进制日志格式：
        1.二进制日志并非直接记录每一条sql语句，而是以事件的形式记录每次执行的sql操作；包括：
            1.事件的起始id；
            2.事件的结束id；
            3.事件开始时的时间；
            4.事件的内容(即执行过的sql)；

        2.二进制日志以二进制方式记录，需要通过mysql提供的mysqlbinlog工具查看，不能直接使用文本工具查看和处理；mysqlbinlog工具使用方式如下:
            -d,--database=name：只查看指定数据库的日志操作
            -o,--offset=#：忽略掉日志中的前n个操作命令
            -r,--result-file=name：将输出的日志信息输出到指定的文件中，使用重定向也一样可以。
            -s,--short-form：显示简单格式的日志，只记录一些普通的语句，会省略掉一些额外的信息如位置信息和时间信息以及基于行的日志。可以用来调试，生产环境千万不可使用
            --set-charset=char_name：在输出日志信息到文件中时，在文件第一行加上set names char_name
            --start-datetime,--stop-datetime：指定输出开始时间和结束时间内的所有日志信息
            --start-position=#,--stop-position=#：指定输出开始位置和结束位置内的所有日志信息
            -v,-vv：显示更详细信息，基于row的日志默认不会显示出来，此时使用-v或-vv可以查看

        3.二进制日志到的格式分为三种：
            1.在mysql5.1之前使用statement这种格式记录，这种格式下，事件的内容直接记录发生的sql语句；示例如下：
                mysqlbinlog ./mysql-bin.000001
                /*!*/;
                # at 379  (当前事件的起始id)
                #200605 14:22:49 server id 1  end_log_pos 487 	Query	thread_id=3360	exec_time=0	error_code=0 (事件发生时的一些信息)
                SET TIMESTAMP=1591338169/*!*/;
                update tuser set uname = 't21' where uid = 2  (事件内容，即执行过的sql语句)
                /*!*/;

            2.在mysql5.2之后，提供了row这种格式，并不直接记录发生过的sql语句，其格式如下：
                mysqlbinlog ./mysql-bin.000001 -vv  (查看row格式的binlog时要带上-vv，否则看不到事件的详细内容)
                '/*!*/;
                ### UPDATE `ptest`.`tuser`
                ### WHERE
                ###   @1=2 /* INT meta=0 nullable=0 is_null=0 */
                ###   @2='t21' /* VARSTRING(15) meta=15 nullable=0 is_null=0 */
                ###   @3=21 /* TINYINT meta=0 nullable=0 is_null=0 */
                ### SET
                ###   @1=2 /* INT meta=0 nullable=0 is_null=0 */
                ###   @2='t22' /* VARSTRING(15) meta=15 nullable=0 is_null=0 */
                ###   @3=21 /* TINYINT meta=0 nullable=0 is_null=0 */
                # at 682
            
            3.在mysql5.1之后，默认使用mixed这种方式记录日志，即普通的sql操作以statement这种格式记录，以下情况则使用row格式记录：
                1.表的存储引擎为NDB，这时对表的DML操作都会以row的格式记录。
                2.使用了uuid()、user()、current_user()、found_rows()、row_count()等不确定函数。但测试发现对now()函数仍会以statement格式记录，而sysdate()函数会以row格式记录。
                3.使用了insert delay语句。
                4.使用了临时表。
            
            线上环境推荐使用row这种格式，否则在RC隔离级别下，如果使用主从配置，会有数据不一致的问题产生；

        4.使用二进制日志定点还原数据：
            1.还原方式1：使用--stop-datetime指定截止日期：
                mysqlbinlog --stop-datetime="2018-4-2 11:37:21" /data/mysql-bin.000001 | mysql -u user -p password
            2.先将binlog导出为sql，然后再加载sql来恢复：
                mysqlbinlog /data/mysql/mysql-bin.000001 > /tmp/c.sql
                mysql -u root -p password -e "source /tmp/c.sql"
            3.恢复多个二进制日志：
                mysqlbinlog mysql-bin.[*] | mysql -u root -p password

        5.删除二进制日志：
            1.reset master;  将会删除所有二进制日志，新的二进制日志从000001开始命名；
            2.PURGE { BINARY | MASTER } LOGS { TO 'log_name' | BEFORE datetime_expr }：
                该命令用来删除二进制日志至指定日期或者文件：
                1.删除至指定文件：purge master logs to "mysql-bin.000006";
                2.删除至指定日期：purge master logs before '2018-11-29 03:02:35';
            3.在配置文件中配置，定时删除二进制日志：--expire_logs_days=N  每隔N天之后，二进制日志自动清空

        6.查看二进制日志信息：
            show binary logs：显示当前数据库中有哪些二进制日志文件；
            show binlog events in 'xxx-bin.000005'：显示当前二进制日志文件中有哪些类型的事件；
            show master status：显示主从配置中主服务器的二进制日志信息；
        7.和二进制日志相关的变量：
            1.启动相关：

                log_bin = {on | off | base_name} #指定是否启用记录二进制日志或者指定一个日志路径(路径不能加.否则.后的被忽略)
                sql_log_bin ={ on | off } #指定是否启用记录二进制日志，只有在log_bin开启的时候才有效
            2.过滤数据库：
                binlog_do_db = #明确指定要记录日志的数据库
                binlog_ignore_db = #指定不记录二进制日志的数据库
            3.性能相关：
                binlog_cache_size = 32768 #基于事务类型的日志会先记录在缓冲区，当达到该缓冲大小时这些日志会写入磁盘
                max_binlog_cache_size = #指定二进制日志缓存最大大小，硬限制。默认4G，建议不要改
                binlog_cache_use：使用缓存写二进制日志的次数(这是一个实时变化的统计值)
                binlog_cache_disk_use:使用临时文件写二进制日志的次数，当日志超过了binlog_cache_size的时候会使用临时文件写日志，如果该变量值不为0，则考虑增大binlog_cache_size的值
                sync_binlog = { 0 | n } #这个参数直接影响mysql的性能和完整性
                    sync_binlog=0:不同步，日志何时刷到磁盘由FileSystem决定，这个性能最好。
                    sync_binlog=n:每写n次二进制日志事件(不是事务)，MySQL将执行一次磁盘同步指令fdatasync()将缓存日志刷新到磁盘日志文件中。Mysql中默认的设置是sync_binlog=0，即不同步，这时性能最好，但风险最大。一旦系统奔溃，缓存中的日志都会丢失。
            4.关于文件大小:
                expire_logs_days = #指定自动删除二进制日志的时间，即日志过期时间
                max_binlog_size = #指定二进制日志文件最大值，超出指定值将自动滚动。但由于事务不会跨文件，所以并不一定总是精确。
                binlog_format = { mixed | row | statement } #指定二进制日志基于什么模式记录
            
1.sql预优化排查
2.undo log和redo log
3.分库分表组件及常见策略

                        

                
                


            


            





            


                

                    
                    


    




