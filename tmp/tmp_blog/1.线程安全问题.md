# 多线程并发执行时的线程安全问题

## 1.线程间并发执行时的特征：

### 1.优势：

​		1.多条线程共同执行同一个任务，提升任务本身执行效率；

​		2.多条线程分别执行不同任务，协调运行完成系统功能；

### 2.劣势：

​		1.因为线程的抢占式执行方式无法保证线程间操作的原子性；即线程执行当前代码期间可能失去执行机会，然后执行其他线程中的代码，造成运行结果和预期结果不符；

​		2.因为java的内存模型而无法保证线程间共享数据的可见性；一个线程在其私有内存空间内修改了共享数据，那么其他线程内无法看到该数据已经被修改；

​		3.因为编译器和处理器的优化而无法保证线程执行指令的有序性；编译器以及处理器为了提高指令执行效率，会调整指令的执行顺序，实际执行指令的顺序可能和源码中顺序不同，造成运行结果和预期结果不符；

​		上述这些问题统一称为线程安全问题，多线程并发执行引起业务逻辑的错误均可由上述三个方面分析；

## 2.关于原子性：

### 1.原子性和原子性指令：

​        原子是最小的，不可再分割的，因此在程序中使用原子性表示一个最小的执行单元，作为最小的执行单元，同一时刻只会有一个处理器执行该执行单元，并且一旦开始执行就必须执行完成或者发生异常之后终止，中途不应该暂停下来然后执行其他执行单元；

​		原子性指令就是值具有原子性特征的指令，处理器在执行原子性指令时只有发生异常或者执行完成之后才会终止，只有当前原子性指令终止之后才会执行其他指令或者切换线程；

​		通常情况下，一个最小的具备原子性的执行单元由一个指令组成，但是单个指令并不一定具备原子性，一个指令是否具备原子性取决于处理器如何处理该指令，和指令的语义、个数无关；java中则只定义了8中原子性指令(最常见的就是除过long、double类型的赋值操作)，其余指令或者由多条指令组成的代码块并不具备原子性；

### 2.关于线程同步:

​		线程在执行时是以抢占CPU时间片的方式执行，执行时机并不确定；对于有共享变量访问的多线程环境下，极有可能出现多条线程同时访问一个共享变量，如果条线程基于共享变量同一个值进行操作，那么将会造成后完成线程的更新结果把先完成的线程的更新结果覆盖掉，造成线程安全问题；

​		所以有对共享资源操作的多线程环境都需要线程间以同步的方式执行，也就是需要保证在一个线程执行完代码之后，另一个线程才能执行与当前代码需要同步的代码；

### 3.关于原子性和线程同步的关系：

​		对于同步执行方式而言，要求保证线程执行当前代码块期间不被打断，而且其他线程也必须要等待当前线程执行完毕之后才能执行自己的代码；

​		而当代码具有原子性时，就成为一个最小的执行单元，其执行代码期间不可被打断，只有当前代码块执行完成之后才能执行其他的代码块；

​		因此只需要让线程要执行的代码块具有原子即可实现线程同步执行的需求；

### 4.原子性的实现方式：

​		1.对于本身具有原子性的指令，在执行期间，处理器会保证其原子特征；

​		2.对于不具有原子性的指令，或者由多个指令组成的代码块，则需要手动以加锁的方式实现其原子特征；

### 5.java中保证代码原子性的方式：	

​		java中通过以下两种方式(乐观锁/悲观锁)实现代码块的原子性：

​			1.悲观的方式：加锁，主动加锁的方式；

​			2.乐观的方式：CAS，比较并赋值的方式；

​		两种实现原子性方式的原理不同，性能以及适用场景也有所不同；通常情况下，如果是需要保证多条代码执行的原子性，则需要使用加锁的方式；如果是将某个变量修改为新值则通过CAS的方式即可；

### 4.加锁的方式和原理：

#### 1.加锁实现原子性的原理:

​		主动加锁即认为当前操作一定会发生线程间竞争，是一种悲观的方式；

​		对于需要保证同步执行的相同或者不同代码块需要使用同一把锁锁住，线程在执行被锁住的代码之前必须先获得该锁，只有获得锁的线程才能执行代码，而未获得锁的线程则不能执行代码，只能处于阻塞等待状态；直到持有锁的线程释放锁之后，其他等待该锁的线程才能继续竞争锁，竞争到锁的线程才能执行其需要执行的同步代码块，而未竞争到锁的线程则继续处于阻塞等待状态；

​		所谓加锁则是指为某个对象加锁，并非是为代码加锁，可以使用同一把对象锁锁住任意需要同步执行的代码块；

#### 2.加锁的方式：

​		java中提供了两种加锁方式：synchronized和Lock；

#### 3.关于synchronized加锁:

​		synchronized是java提供的一个关键字，用来保证代码以原子性方式执行；

​		synchronized既可以修饰静态方法、实例方法也可以修饰代码块；

##### 1.synchronized修饰静态方法:

````java
public synchronized static void fun(){
  // synchronized修饰静态方法
}
````

##### 2.synchronized修饰实例方法:

```java
public synchronized void fun(){
  // synchronized修饰实例方法
}
```

##### 3.synchronized修饰代码块:

```java
public Object lock = new Object();
public void fun(){
  synchronized(lock){
    // synchronized修饰代码块
  }
}
```

##### 4.synchronized修饰方法和代码块的区别:

​	1.synchronized如果直接修饰一个方法，会在编译完成后将该方法属性表中的synchronizedAccess属性设置为1，运行期间调用该方法时，会先检测该方法该属性是否为1，如果为1则先执行加锁逻辑，等到方法执行完成之后或者执行期间遇到异常、wait时才会主动释放锁；如果synchronized修饰一个代码块，编译完成之后会生成一个moniterenter指令和两个moniterexit指令，moniterenter指令和第一个moniterexit指令对应同步代码的入口和出口，同时为了保证在代码发生异常之后能够释放锁对象，编译器会隐式的添加一个异常处理块，并在finally中添加moniterexit指令；

​	2.synchronized修饰方法时，锁住的是整个方法，加锁粒度较大，并发度较低；实际使用时，如果需要同步的代码仅仅只是一小段代码块，那么可以使用synchronized锁住代码块来减小锁粒度，然后通过双检机制来确保共享变量的访问安全；

​	3.synchronized修饰静态方法时，其锁对象是静态方法所在类的Class对象，修饰实例方法时，锁对象是调用当前方法的实例对象；而修饰代码块时，可以手动指定任意对象作为锁对象；

##### 4.关于synchronized加锁细节：

###### 1.概述：

​		在JDK1.6之前，synchronized使用系统的竟态条件mutex来实现锁的竞争，加锁时直接申请重量级锁，一旦没有获取到锁线程将立即进入阻塞等待状态，性能较差；

​		在JDK1.7之后，优化了synchronized，有了锁升级的过程，升级方向为：**偏向锁->轻量级锁->重量级锁**；并且加入了**锁消除、锁粗化**机制，使得synchronized性能大幅提升；

###### 2.关于偏向锁：

 1.偏向锁解决的问题：

​		同一个线程反复加锁和释放锁时效率的优化；对应业务场景主要是在单线程环境下使用synchronized保证线程安全的二方库和三方库；

 2.偏向锁加锁细节流程：

​	1.从遇到monitorenter指令开始指向加锁流程；

​	2.获取当前锁对象；

​	3.遍历线程栈，找到一个地址最高且空闲的Lock Record：

​		1.Lock Record由两个类：BasicObjectLock和BasicLock组成；用来存储当前线程持有锁的信息；

​		2.BasicObjectLock成员：BasicLock和_obj；BasicLock成员：_displaced_header；

​		3.之所以要查找地址最高的空闲Lock Record目的则是为了保证线程持有锁的顺序；

​		4.而所谓的空闲Lock Record则是指obj字段为null的BasicObjectLock;

​		5.查找过程中如果遇到Lock Record的obj字段就是当前锁对象则退出查找过程；

​	4.然后将Lock Record的obj字段赋值为当前锁对象；

​	5.获取锁对象的mark word；

​	6.检测锁对象的mark word是否已经处于偏向模式；

​	7.如果已经处于偏向模式则做以下检查：

​		1.检测当前锁对象的mark word中的threadid字段是否指向当前线程；如果threadid指向当前线程，并且锁对象的epoch和其class的epoch相同，则说明同一个线程在此获取锁，直接返回true即可；否则执行下一步检查：

​			*1.之所以要检查epoch值，是因为虚拟机会在锁对象所属类中设置里一个计数器和epoch值，每当该类的对象发生一次偏向锁撤销时，该计数器就会加1，当该计数器的值超过20之后，将会把epoch值加1；

​			*2.之所以这么做，是为了优化同一个类有大量对象发生了偏向锁升级为轻量级锁然后被另一个线程持有的情况，触发了批量重偏向之后，后续该类的对象在此被其他线程持有时将不会先撤销后升级，而是直接使用CAS的方式将对象内部的threadid指向新的线程即可，提升重偏向效率；

​			*3.如果只是同一个线程反复持有锁对象，而没有发生大量锁撤销时，那么锁对象的epoch值和其类class对象中的epoch值应该是相等的；如果发生了锁的批量重偏向，那么无论是其他线程获取多对象，还是当前线程在此获取锁对象，此时锁对象的epoch值和其class中的epoch值一定是不相等的；这个机制仅仅只是为了记录是否发生过重偏向而已；

​		2.检测该锁对象所属类的偏向模式是否关闭，如果已经关闭，则说明发生了批量撤销，通过CAS将该对象的对象头替换为其类class对象的对象头，如果没有关闭则执行以下检测：

​			*1.如果一个类的对象发生锁撤销的次数超过40次，虚拟机将认为该类的锁对象不适合用作偏向锁，将会在类中关闭偏向模式；之后如果继续使用该类的对象作为锁对象时，将从轻量级锁开始升级；

​			*2.这么做主要是为了优化不适用偏向锁而又没主动关闭偏向锁的业务场景；

​			*3.如果已经发生了批量撤销操作，那么直接升级为轻量级锁；

​		3.检测当前锁对象和和其class对像中的epoch值是否相等，如果不等说明至少发生了批量重偏向，而且上一步检测到也没有发生批量撤销，那么说明此时处于批量重偏向状态，则直接将锁对象重偏向即可当前线程即可；

​			*1.构造一个指向当前线程的markword，然后通过CAS的方式替换掉锁对象，如果替换成功，那么说明锁对象已经重新偏向当前线程，否则说明发生了竞争，需要升级为轻量级锁；

​		4.如果上述三步检测都未通关，那么说明此时锁对象偏向其他线程，需要升级为轻量级锁然后被当前线程持有，或者当前锁对象处于匿名偏向状态；

​			*1.构造一个偏向当前线程的mark word，然后通过CAS的方式将锁对象的mark word由匿名偏向状态替换为指向当前线程的状态，如果替换成功则由当前线程持有，否则说明发生了竞争，需要升级为轻量级锁状态；

​	5.如果上述流程没有成功，那么说明当前发生竞争，需要升级为轻量级锁，此时会先创建一个无锁的Markword；然后设置给Lock Record的displaced_header；继续检测是否是锁重入，如果是，则将displace_header设置为null；否则将无锁的markeord设置给displaced_header，是因为在轻量级锁解锁时时直接将displaced_header中的值通过CAS的方式设置给锁对象的markword；(轻量级锁解锁之后锁对象的markword头是无锁状态)

3.偏向锁撤销流程：

​	1.偏向锁撤销不是指偏向锁释放，而是指当前偏向锁的状态不满足直接偏向当前线程的条件，需要将偏向锁撤销，然后升级为轻量级锁的过程；上述偏向锁加锁失败之后的情况都将先走入偏向锁撤销流程，除此之外，当对象已经发生偏向之后又调用了其hashcode方法时，也会走入锁撤销流程；

​	2.偏向锁的撤销需要等到达安全点之后才能执行，在到达安全点之后会先检测持有偏向锁的线程是否存活以及持有偏向锁的线程是否退出同步代码块；

​	3，如果持有偏向锁的线程存活而且还未退出同步代码块，那么将锁升级为轻量级锁，并让锁对象的owner指针指向原持有偏向锁的线程；

​	4.否则将锁对象设置为无锁状态；然后让竞争该锁的线程执行轻量级锁加锁流程；

​	3.偏向锁对象是应该撤销为无锁状态，然后升级为轻量级锁还是直接重偏向至另一个线程，与持有该偏向锁对象的线程是否执行完毕没有关系，只取决于当前锁对象是否处于批量重偏向状态；

4.偏向锁的解锁：

​	偏向锁解锁仅仅只会将当前线程中Lock Record中的obj设置为null即可，并不会替换锁对象的mark word；当前线程执行完同步代码块之后就会自动解锁，而检测当前线程是否执行完同步代码块的方式就是遍历锁对象markword中threadid指向线程中的所有Lock Record记录，查看是否有obj为当前锁对象的Lock Record；如果没有则说明线程已经退出同步代码块，否则说明线程还在同步代码块中；	

###### 3.关于轻量级锁：

​	1.轻量级锁使用场景：

​		1.轻量级锁是为了解决多线程环境中线程之间存在竞争，但是竞争不多的场景；如果线程间竞争不激烈，而且持有锁的时间比较短，那么显然没有必要在线程获取不到锁的时候直接进入阻塞状态；否则可能出现一个线程刚刚进入阻塞状态另一个线程就已经释放了锁，那么又需要立即唤醒这个线程，而线程阻塞和唤醒都是重量级操作，如此将造成性能下降；

​	   2.轻量级锁的做法就是当前线程进入自旋，然后在自旋过程中将锁对象Mark word中的指向Lock Record指针指向当前线程中LockRecord；如果在自旋中上述操作成功那么就表明当前线程获得锁，否则在超过一定次数之后会将锁膨胀为重量级锁；

​	   3.轻量级锁的本质则在于让等待锁的线程不停的运行等待锁，而不是立即将线程挂起；借此避免频发挂起线程和唤醒线程导致效率降低；

​	2.轻量级锁加锁时机：

​			轻量级锁由偏向锁升级而来，而偏向锁是为了解决单线程运行时频繁加锁和释放锁对效率带来的影响，那么如果在多线程环境下多个线程争抢同一把偏向锁时，该锁将会升级为轻量级锁，具体有以下场景：

​			1.当前锁对象已经偏向另一个线程，并且其所属class没有发生批量重偏向；无论另一个线程是否存活、是否退出同步代码块，只要当前线程获取锁对象时，锁对象已经处于偏向状态，而且其偏向的线程id不为当前线程，那么就会升级为轻量级锁；

​			2.当锁对象发生了批量重偏向，那么在将锁对象的mark word替换为指向当前线程的mark word时如果CAS失败，那么说明发生了竞争，此时也会升级为轻量级锁；

​			3.当前锁对象所属class已经发生了批量撤销操作，那么该锁对象不再适合作为偏向锁机制，使用该锁对象加锁时将会从轻量级锁开始升级；

​			4.当前锁对象处于匿名偏向状态，然后将锁对象的mark word替换为指向当前线程的mark word时CAS操作失败，那么说明发生了线程竞争，此时也将升级为轻量级锁；

​			5.通过参数关闭了JVM的偏向锁，那么加锁时将会从轻量级锁开始升级；

​	2.轻量级锁加锁流程：

​		1.由于偏向锁撤销之后会将锁对象的Markword设置为无锁状态；所以在升级为轻量级锁时会先检测当前锁对象的mark word是否为无锁状态；

​		2.如果当前锁对象的mark word时无锁状态，那么jvm会在竞争锁的线程中创建一个Lock Record，然后将锁对象的的markword拷贝至Lock Record的displaced_header；之所以这么做是为释放轻量级锁做准备；

​		3.然后通过自旋加CAS的方式将锁对象中指向Lock Record的指针指向当前线程的Lock Record；

​		4.如果第三步成功了，那么就表明该线程拥有了锁对象，此时会将锁对象的mark word的锁标识替换为00；表明锁对象处于轻量级锁状态；

​		5.如果竞争锁失败了，那么检测是否是当前线程的锁重入操作，如果是则向线程中添加一个displaced_header为null的Lock Record，表示当前线程重入了锁对象；

​		6.如果当前线程并非锁重入，那么会继续检测当前是否只有一个线程等待锁，如果是，则线程通过自旋等待；当自旋超过一定次数或者由第三个线程需要获取锁时将会升级为重量级锁；

​		2.将markword中的锁标识为改为000；

​		3.将markword中指向LockRecord的指针指向当前Lock Record；

​	3.轻量级锁重入计数方式：

​		JVM通过在线程栈中添加一个displaced mark word为null的Lock Record来表示锁重入，每重入一次就添加一个这样的LockRecord；

​		JVM为何以这样的方式表示锁重入：	

​			1.锁重入的话必须要记录下来，以便在释放锁时使用，此时要么记录在锁对象的markword中，要么记录在线程中；

​			2.锁对象中的mark word结构比较紧促，已经没有多余的空间记录重入次数了，那么只能记录在线程中；

​			3.如果要记录在线程中，那么只能记录在obj指向当前锁对象的Lock Record中，但是这样的做法代价就在于每次都需要遍历线程的所有LockRecord来找到指向当前锁对象的Lock Record；而直接添加一个指向当前锁对象且displaced_header为null的Lock Record则方便很多；这样做的效率也会更高一些；

4.轻量级锁释放锁的流程：

​		1.通过CAS的方式将obj为当前锁对象的Lock Record中的displace_header设置给锁对象的markword；

​		2.然后将线程栈中Lock Record的obj字段设置为null；	

#### 4.关于Lock和AQS:

##### 1.Lock和AQS简述：

​		1.Lock是应用级别提供的一个具有锁机制的接口，对于锁的占用模式分为独占锁和共享锁，而独占锁又可以分为公平锁和非公平锁，除此之外Lock还支持取消等待锁、返回加锁结果等功能；

​		2.Lock通常用修饰代码块，实现代码块的原子性；

​		3.Lock常用的具体实现类有ReentrantLock，ReentrantReadWriteLock.ReadLock，ReentrantReadWriteLock.WriteLock；

​		4.AQS则是一个队列同步器，用来实现线程的阻塞和释放逻辑；上述Lock的具体实现类均采用了AQS实现锁机制；

##### 2.Lock使用基本方式：

​		1.Lock的具体实现类ReentrantLock是一个可重入锁的具体实现，并且提供了公平锁和非公平锁两种加锁机制，同时支持获取加锁结果；其具体使用方式如下：

​			1.创建锁对象

​				Lock lock = new ReentrantLock(boolean fair);

​				1.如果fair为true则表示使用公平锁FairSync，如果不为true则使用非公平锁NonfairSync；

​				2.FairSync和NonFairSync为ReentrantLock的内部类，都继承自内部类Sync，而内部类Sync则继承自AbstractQueuedSynchronizer抽象类，无论是公平锁还是非公平锁其加锁逻辑最终到依靠AQS来实现的；

​			2.加锁：

​				lock.lock(); 或者 lock.tryLock();

​				1.lock()不会有返回值，如果线程加锁成功，那么将会继续执行相关同步代码，如果加锁失败将会被挂起；

​				2.tryLock()会有返回值，如果线程加锁成功，那么将会返回true，并继续执行相关同步代码，如果加锁失败将会返回false，线程可以根据返回值在线程加锁失败时执行其他代码不用被挂起；

​			3.解锁:

​				lock.unlock();

##### 3.关于ReentrantLock加锁和解锁的本质：

​			1.ReentrantLock是应用级别实现的可重入排它锁，其加锁本质就是通过CAS的方式来修改一个加锁状态变量的值；

​			2.ReentrantLock支持独占锁和共享锁两种模式，两种模式下对表示锁状态的变量修改方式有所不同：

​				1.对于独占锁：

​					1.如果能够将该状态变量的值从0修改为1，那么说明当前线程获得锁，其他未竞争到锁的线程将会被挂起，然后等待被唤醒之后获得锁；

​					2.当线程重入锁时也只需要将状态变量加1即可，而每次解锁则将状态变量的值减1；

​					3.当状态变量的值被减为0时，表明当前线程释放了锁，将会唤醒其他排队等待的线程来获取锁；

​				2.对于共享锁：		

​					1.将锁状态变量设置为一个初始值；

​					2.线程每获取一次共享锁就将该初始值-1；

​					3.当线程将初始值减1之后得到的是负数，那么表示锁资源已经用尽，当前线程需要排队等待；

##### 4.关于对列:

​		1.线程获取锁失败之后，需要挂起然后放入到对列中，AQS中会将线程封装为一个Node节点，并在Node节点中存储线程的id、线程状态、前置节点、后继节点等信息；

​		2.对于Sync Queue：表示用来实现同步锁的对列，是一个双向对列；对于Condition Queue：表示用来实现线程协同时的对列，是一个单向对列；

​		3.Node中存放了线程的状态，在AQS中线程的状态有以下几种：

​			1.1-CANCELLED：表示线程节点已经不再取消继续等待锁，比如超时等；

​			2.-1-SIGNAL表示当前节点被挂起，正在等待被唤醒获得锁；

​			3.-2-CONDITION表示线程在Condition对列中阻塞；

​			4.-3-PROPAGATE表示该线程以及后续线程进行无条件传播，早CountDownLatch中会有使用；

​	   4.等待锁的线程一旦获取到锁之后会将自己设置为头结点，然后在释放锁之后，唤醒下一个状态为-1的线程，由被唤醒的线程持有锁；

##### 5.关于ReentrantLock使用的注意实现；

###### 1.独占锁相关：

​		1.公平锁和非公平锁：

​			1.公平锁是指加锁的线程会按照先来后到的顺序进行排序；非公平锁时值加锁的线程会直接争抢锁，如果争抢不到那么就按照先来后到的顺序排序等待锁；

​			2.公平锁加锁流程：

​				1.创建FairSync实例对象，并调用acquire方法获取锁；

​				2.acquire调用tryAcquire尝试获取锁，在tryAcquire中会首先检测当前状态变量state的值是否已经被修改为1：

​					1.如果state状态变量为0，那么说明锁还未被其他线程持有；然后检测是否有其他线程正在排队等待锁：

​						1.如果没有线程正在等待锁，那么直接通过CAS的方式将状态变量的值由0修改为1；

​							1.如果修改成功，说明当前线程获取到锁，然后将表示持有锁的变量设置为当前线程；

​							2.如果没有修改成功，说明发生了竞争，直接返回false准备排队

​					    2.如果有线程正在排队，那么当前线程也必须先排队，tryAcquire方法将会返回一个false准备排队；	

​					2.如果状态变量不为0，那么说明当前锁已经被每个线程持有，继续检测持有锁的线程是否是当前线程：

​						1.如果是当前线程，那么说明是当前线程重入锁，直接将锁状态变量的值加1即可返回true；

​						2.如果不是当前线程，那么说明发生了竞争，tryAcquire将会返回false，准备排队等待；	

​				3.上述操作返回false，那么就需要进行排队：

​					1.在排队之前需要先将等待锁的线程封装为一个node节点；

​					2.检测同步对列的tail节点是否为null，不为null，则通过CAS的方式将该节点添加至尾节点之后；如果为null则通过CAS的方式将该节点设置为头节点；整个过程是自旋中完成，保证该线程一定能够添加到对列中；然后将封装了该线程的Node节点返回；

​					3.在自旋中获取当前节点的前置节点，并检测前置节点是否为头节点：

​						1.如果是那说明下一个获取锁的线程就是自己，所以会再次调用tryAccquire来获取一下锁：

​								1.如果能够获取到锁对象，然后将头结点设置为当前线程的节点，然后将该节点的后继节点设置为null；

​						2.如果前置节点不是头节点，或者没有获取到锁对象，那么会检测是否需要挂起当前线程：

​							1.检测当前线程的等待状态是否为-1，如果是则返回true准备挂起线程；

​							2.如果其状态大于0，那么说明线程已经发生中断或者已经取消等待，那么会从该节点一直往后查找第一个状态小于0的节点；作为当前正在持有锁的线程的后继节点；保证当前线程释放锁之后能够正确的唤醒线程；

​							3.如果线程的状态为0或者为PROPAGATE，说明当前线程正在等待信号，那么会通过CAS的方式将线程的状态修改为-1；

​					 3.将线程挂起，然后检测线程在等待期间有么有发生中断，由于线程等待期间是不会处理中断的，那么需要在挂起线程之后检测线程是否在等待期间发生中断，如果发生过中断那么需要手动触发器中断；

​		3.非公平锁加锁流程：

​			非公平锁加锁流程和公平锁加锁流程相似，只是非公平锁不会检测状态变量是否为0，不会检测是否有正在排队的线程，而是直接申请锁对象；如果没有申请到锁对象时后续流程和公平锁加锁流程相同；

​			具体体现在两点：

​				1.非公平锁在调用Lock之后，会立即通过CAS来获取锁，如果获取到则当前线程持有获取到的锁；

​				2.如果没有获取到锁，那么非公平锁也不会检测是否有其他线程正在排队等待，而是检测到锁状态变量为0时立即通过CAS获取锁；

​		4.释放锁流程：

​				1.每次调用unlock方法时会将锁状态变量-1，因为该状态变量被该线程单独持有，所以无需考虑线程安全问题；如果锁状态变量的值被减为0时，将会调用unpark方法来唤醒后续还在等待锁线程；

###### 2.共享锁相关：

​		1.共享锁由Semaphore具体实现，同样共享锁也有公平锁和非公平锁的区别，具体由AQS实现；

​		2.共享锁获取思路：

​			在获取共享锁时，会将锁状态变量初始化为一个固定值，每次线程获取锁时会将该锁状态变量减1:

​				如果减完之后返回0表示该线程获取到锁，但是后续线程无法再获取锁;

​				如果返回整数，那么说明还有锁可以继续被其他线程获取;

​				如果返回负数，表示当前线程获取锁失败；

​				获取失败之后将会添加到对列的尾部；等待由资源之后唤醒；

##### 6.关于Condition

###### 1.关于Condition:

​		1.Condition相当于一个监视器，用来监视和改变线程运行状态；

​		2.Condition提供了await和signal以及signalAll方法来模拟Object的wait、notify、notifyAll方法；实现线程的阻塞和唤醒；

2.Condition的基本使用方式：

​	Lock lock = new ReentrantLock();

​	Condition con = lock.newCondition();

​	Condition con1 = lock.new Condition();

​	con.await()

​	con1.await()

​	con.signal()

​	con1.signal()

​	con.signalAll()

3.Condition和Lock搭配实现线程状态管理的流程分析；

​	1.Condition作用原理：

​		在AQS内部维护了一个双向对列，即Sync Queue，只有在Sync Queue的线程才能被依次唤醒然后获的锁；所以通过Lock保证同一时刻只会有一个线程在执行同步代码；

​		除此之外，在通过Lock调用newCondition时，也会维护一个Condition queue；当线程获取到锁之后，执行了await方法时，该线程会释放掉所有的锁，然后从Sync queue中出对列，并将该线程封装为一个状态为PROPAGATE的节点，放在condition queue中；

​		等到其他线程调用signal或者signalAll方法时才会将condition queue对列中的节点全部退出，然后添加到sync queue中；等待被唤醒然后竞争锁；

​	2.await方法：

​		1.检查线程是否发生中断，如果已经发生中断，那么直接抛出中断异常；

​		2.创建一个conditionWaiter，并放图condition queue对列尾部；

​		3.释放当前线程持有的所有锁，当前线程可能因为重入而持有多个锁，此时会一并释放；然后将其持有的锁保存，以便在唤醒之后能够继续加上响应的锁；

​		4.挂起当前线程，直至遇到唤醒信号或者被中断；

​	3.signal：

​		1.遍历condition queue，查找到需要被唤醒的线程；

​		2.从condition queue中移除该线程对应的节点；

​		3.将节点移动至sync queue中，等待被唤醒；

​	4.signalAll()：

​		1.遍历condition queue；将对列中所有的节点全部移动至sync queue中等待被唤醒；

#### 5.synchronized和Lock的区别:

​	两者选择的已经注要集中在两个方面：性能和功能；

​	关于性能差异：

​		在JDK1.6之前：由于synchronized以mutex的方式加锁，使用的是系统级别的竟态条件，而且加锁逻辑简单只要未竞争到锁，线程将会立即进入阻塞等待状态；而Lock是在应用级别实现的竟态条件，并且在未获取到锁之前还会有自旋等待；因此synchronized相对于Lock而言性能较差，常常选择Lock作为加锁方式；

​		但是在JDK1.6之后：synchronized做了较多的优化，加锁流程细化，有了锁升级、锁消除等优化点，其性能相较于Lock并不差，如果使用得当甚至synchronized的性能还会超出Lock，因此在JDK1.6之后对于synchronized和Lock的选择，性能已经不是决定因素，更多的是因为两者所提供的功能不同；

​	关于功能差异：	

​			1.synchronized是java提供的关键字，用来修饰一个方法或者锁住一段代码块；而Lock是应用级别提供锁机制的接口，只能用来锁住代码块；

​			2.使用synchronized时，如果发生异常、线程wait、或者同步代码块执行完成后会自动释放持有的锁；而Lock则需要手动释放锁；

​			3.synchronized是不可中断的，而Lock则允许中断；

​			4.synchronized无法获取加锁结果，但是Lock可以获取加锁结果；

​			5.synchronized加的锁是非公平锁，而Lock可以选择加公平锁或者非公平锁；

​			6.synchronized加的锁是排它锁，而Lock则除过排他锁以还提供了能够提高读写并发度读锁和写锁；

### 5.CAS的原理和使用方式:

#### 1.CAS的原理：

​		1.CAS是compare and swap的缩写，即先比较后交换，属于乐观锁的思想；虽然CAS有两步操作，但实际上操作系统提供了具有原子性的CAS指令，能够让两步操作像一步操作一样原子性的执行；

​		2.CAS的作用原理是：在设置一个共享变量的值之前，先检测该共享变量有没有被修改过，如果没有被修改过则直接将其修改为新值即可；如果有被修改过则放弃修改或者自旋重新计算新值然后修改直至成功；

​		3.CAS具体逻辑：CAS中有三个值参与：变量旧值、变量现值、变量新值；在设置变量新值时如果变量旧值=变量现值，那么说明变量没有被修改过，可以直接赋予新值，否则说明变量在当前线程计算新值期间已经被修改了，那么应该放弃设置新值；

​		4.java中通过unsafe相关类提供CAS操作指令，用来以同时基于Unsafe提供了相关Atomic系列类库来实现CAS功能；

#### 2.CAS的具体实现:Unsafe和Atomic

​		1.关于Unsafe：

​			Unsafe是java提供的执行CAS指令的类库，其中包含了系列compareAndSwapXxxx等方法以及getAndSetXxxx和getAndAddXxxx方法，用来实现比较并交换的功能；但实际上需要用到CAS相关功能时均使用基于Unsafe实现的Atomic相关类库；

​		2.关于Atomic：

​			1.java在java.util.concurrent.atomic包下提供了系列原子性类库，常用的如：

​				1.AtomicBoolean、2.AtomicInteger、3.AtomicLong、4.AtomicReference、5.LongAdder、6.AtomicStampedReference;

​			2.对于上述类库均提供了以下方法：

​				所有的原子引用类均提供了以下四种方法；

​					1.get()：获取该原子引用类型的值；

​					2.set(E e)：设置原子引用类型的值；

​					3.getAndSet(E e)：获取旧值，设置新值，并返回旧值；

​					4.compareAndSet(E expect，E update)：比较并设置新值，并返回布尔值表示是否设置成功；

​			对于2.AtomicInteger和3.AtomicLong还提供了以下方法：

​					5.getAndIncrement()；自增1，并返回旧值；incrementAndGet()：自增1，并返回新值；

​					6.getAndDecrement()；自增-1，并返回旧值；decrementAndGet()：自增-1，并返回新值；

​					7.getAndAdd()；自增自定义值，并返回旧值；addAndGet()：自增自定义值，并返回新值；

#### 3.CAS缺陷:

##### 1.ABA问题:

​	1.CAS是指比较并交换，而所谓的比较是指在设置新值之前，比较变量的当前值是否是计算新值之前获取到的旧值，如果是那么就说明变量没有被修改过，否则说明变量已经被修改过了，该新值已经失效；

​	但是在多线程环境中可能出现一个线程先将旧值A修改为一个新值B，另一个线程又将新值B修改为了旧值A，那么当前线程在进行比较后交换时会发现当前变量的旧值A就是计算新值时获取到的旧值A，会认为当前变量没有被修改过，然后直接设置了新值，最终导致计算结果错误；这种现象称之为ABA问题；

​	2.ABA问题通常通过版本号来解决，在每次修改变量的值时也需要对版本号自增1；那么在为变量设置新值时需要同时检测变量的旧值和版本好是否被修改过，如果变量值或者版本号任意一个被修改过，那么本次CAS就应该放弃；

​	3.Java中在juc包下提供了AtomicStampedReference类来解决CAS中的ABA问题；也就是在计算新数据之前需要先获取旧值和旧的版本号，在设置新值时除过要给予期望旧值以外和新值以外，还有给予期望旧的版本号和新的版本号，实际应用中如果不在意中间过程，只在意最终结果是否正确，那么不必使用版本号来解决ABA问题；

##### 2.CAS+自旋性能问题:

​	 CAS虽然属于乐观锁，但是本身并无任何加锁操作，所以CAS本身性能很高；但是在多线程环境中如果竞争极其激烈，那么会造成CAS访问的变量成为一个热点，导致众多线程无法一次修改成功，如果此时搭配有自旋操作，那么会有较多线程反复进入自旋流程，最终造成cpu处理时间的浪费，导致性能较低；

​	 java提供了DoubleAdder和LongAdder来解决该问题，其核心思想就在于分散热点；将本来由一个变量形成的热点分散到一个数组的每一位上，增加单个线程修改的成功率，降低自旋的几率，提高性能；

​	LongAdder和DoubleAdder其本质上仍然是就要CAS实现的原子引用类；其实现原理如下：

​		1.相比较于Atomic将热点集中在一个变量上而言，LongAdder则将热点分散在一个数组的不同位置；避免CAS+自旋这种模式在竞争激烈的情况下频繁失败进入自旋造成cpu运行时间的浪费；LongAdder的核心思想就在于分散热点；	

​		2.LongAdder中提供了add、increment、decrement实现LongAdder的增加、sum则用来获取longAdder的值、reset用来重置LongAdder的值；

​		3.由于LongAdder将原本一个变量的值分散在一个数组的不同位置，大幅提升了运算效率，但是该变量的值则需要实时调用sum函数来计算，计算过程由于没有采取任何同步措施，因此其结果并不完全准确；这种拆分热点的思路在ConcurrentHashMap中计算元素总数时也有用到；	

## 2.关于可见性：	

​		此处的可见性表示线程间内存的可见性，即一个线程是否能够看到另一个线程对共享变量的修改；

### 1.java内存模型:

​	1.java中将内存空间分割为两中类型，即主内存和线程私有内存；主内存中存储的数据被所有线程共享，而线程私有的内存则只能被持有的线程访问；

​	2.java中规定，所有的共享变量全部存储在主内存中，线程访问共享变量时，必须将主内存中的变量拷贝至线程私有内存中，然后在私有内存中进行处理，处理完成之后需要将共享变量的新值刷新至主内存中；

### 2.导致内存不可见的原因:

​	1.由于线程在处理共享变量时，处理的是拷贝至线程私有内存的变量值，而线程的私有内存只有持有的线程才能访问，其他线程无法访问，因此一个线程无法看到另一个线程对共享变量做出的修改，造成共享变量在多线程间的不可见；

### 3.保证内存可见性的条件:

### 4.java中保证内存可见性的方式及其原理:

​	1.synchronzied:

​		jvm规范中要求：

​		在进入synchronized修饰的同步代码块中访问全局变量时，需要从主内存中读取变量的值至线程私有内存中；

​		在退出synchronized修饰的同步代码块时，需要将线程私有内存空间中的全局变量最新值刷新至主内存中；

​	因此，在synchronized同步代码块中，首次访问共享变量的值获取到的一定是主内存中最新的值；如果使用synchronized关键字将所有访问同一个变量的代码锁住，那么即可保证同一时刻只会有一个线程能够访问共享变量并且始终能够看到共享变量的最新值；

​	2.volatile：

​		volatile解决线程间共享数据的不可变性是通过系统级别的一致性协议来解决的；

​		每个处理器内部都会有缓存机制来缓存主内存中的数据；但是多个处理器同时需要将各自缓存中的数据设置到同一块内存区域时将发生一致性问题；所以系统的一致性协议规定，在一个处理器向内存中写入的数据是共享变量的数据时，将会通知其他处理器，将其他处理器中的共享数据失效；那么其他处理器中如果需要访问共享数据时将必须从内存中从新读取数据来保证数据在不同处理器中的可见性；

​		而系统之所以能够发现数据失效，是因为每个处理器都会采用嗅探机制来检查数据总线上传播的数据是否是自己持有的数据以及该数据是否已经被修改，如果满足上述条件那么将会认为该数据已经过期；

## 3.关于有序性:

​		此处的有序性并非指线程间按照顺序依次执行，而是指单个线程内指令的执行顺序是否和源码中的书写顺序一致；为了能够最大化提升程序执行的效率，编译器和处理器均会对源码的顺序进行调整，最终执行程序时的代码顺序不一定是源码中的顺序；

### 1.关于指令重排序:

​	1.为了能够提高指令的执行顺序，编译器以及处理器都会调整指令的顺序，注意包括以下三种方式的重排序：

​		1.编译器优化的重排序；编译器会在不改变单线程语义的情况下对指令重新排序；

​		2.指令级并行的重排序；现代处理器会采用指令并行技术将指令重叠执行，为此处理器会调整指令顺序，然后将没有数据依赖关系的指令重叠执行；

​		3.内存系统的重排序；

​	2.为了避免重排序对程序运行结果带来影响，系统规定，重排序必须遵守as-if-serial语义；所谓的as-if-serial是指，无论在哪个维度如何进行指令重排序，都需要保证单线程下的运行结果不会改变；

### 2.无法保证有序性带来的问题:

​	1.as-if-serial语义虽然能够保证单线程环境下运行结果不受影响，但是在多线程环境下，如果一个线程依赖另一个线程对边变量的设置顺序，那么在并发执行的场景下可能会引起线程的执行结果发生改变；

​	2.为此java提出了happens-before规则用来保证一个线程对共享变量的修改指令一定早于另一个线程对共享变量的查看指令；即一个操作的结果要对另一个操作可见，那么这两个操作必须满足happens-before规则；

​	3.java原生遵守以下happens-before规则：

​		程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作； 

​		锁定规则：一个unLock操作先行发生于后面对同一个锁lock操作； 

​		volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 

​		传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 

​		线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 

​		线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 

​		线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 

​		对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；

### 5.volatile能够禁止指令重排序的原理:

​	1.volatile通过插入内存屏障来禁止指令重排序达到happens-before的要求；

​	2.volatile会在写操作前和后分别插入一个storestore内存屏障来禁止当前写操作上面的写以及下面的读操作和当前写操作重排序；会在读操作之后插入一个LoadLoad内存屏障和一个LoadStore屏障来禁止下面的读和下面的写与当前写操作重排序；

### 6.volatile和synchronized配合实现单利模式:

​	使用volatile和synchronized结合双检机制来实现单利模式的方式如下：

```java
public class Singleton{
  private singleton(){}
  private volatile static Singleton instance;
  public static Singleton getSingleton(){
    if(null == instance){
      synchronized(Singleton.class){
        if(null == instance){
          instance = new Singleton();
        }
      }
    }
    return instance;
  }
}
```

在上述代码中为了线程安全和性能考虑，使用了双检配合synchronized来实现单利模式，但是对于单利实例本身则用来volatile修饰，目的并不是为了保证线程间的可见性，而是为了避免指令重排序，避免构造函数在对象真正初始化完成之前就已经执行完将对象的引用返回；导致其他线程拿到一个未完全初始化的对象；

